{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14597ad3-3df7-4d05-bd05-7bedb4a01954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c218f77-d21b-41d3-96a3-114bcf85ed97",
   "metadata": {},
   "source": [
    "Loading pretrained VGG Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7ff3e-9819-494c-b59d-d591bfa9c921",
   "metadata": {},
   "source": [
    "## Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fad2c7d-e246-4cb8-9f8c-bffc5a481727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>A man in a pink shirt climbs a rock face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>A man is rock climbing high in the air .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>A person in a red shirt climbing up a rock fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>A rock climber in a red shirt .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>A rock climber practices on a rock climbing wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  \\\n",
       "0      1000268201_693b08cb0e.jpg   \n",
       "1      1000268201_693b08cb0e.jpg   \n",
       "2      1000268201_693b08cb0e.jpg   \n",
       "3      1000268201_693b08cb0e.jpg   \n",
       "4      1000268201_693b08cb0e.jpg   \n",
       "...                          ...   \n",
       "40450   997722733_0cb5439472.jpg   \n",
       "40451   997722733_0cb5439472.jpg   \n",
       "40452   997722733_0cb5439472.jpg   \n",
       "40453   997722733_0cb5439472.jpg   \n",
       "40454   997722733_0cb5439472.jpg   \n",
       "\n",
       "                                                 caption  \n",
       "0      A child in a pink dress is climbing up a set o...  \n",
       "1                  A girl going into a wooden building .  \n",
       "2       A little girl climbing into a wooden playhouse .  \n",
       "3      A little girl climbing the stairs to her playh...  \n",
       "4      A little girl in a pink dress going into a woo...  \n",
       "...                                                  ...  \n",
       "40450           A man in a pink shirt climbs a rock face  \n",
       "40451           A man is rock climbing high in the air .  \n",
       "40452  A person in a red shirt climbing up a rock fac...  \n",
       "40453                    A rock climber in a red shirt .  \n",
       "40454  A rock climber practices on a rock climbing wa...  \n",
       "\n",
       "[40455 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/captions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cddcd0d1-3a22-41b3-a031-f79c36202e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flicker8Dataset(Dataset):\n",
    "    def __init__(self, captions_file, imgs_dir, transform=None):\n",
    "        self.captions = pd.read_csv(captions_file)\n",
    "        self.transform = transform\n",
    "        self.img_filepaths = [f for f in os.listdir(imgs_dir)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.img_filepaths[idx]\n",
    "        curr_img = os.path.join(\"Data\", \"Images\", img_filename)\n",
    "        curr_lbls = list(self.captions[self.captions[\"image\"] == img_filename][\"caption\"])\n",
    "        img_arr = np.array(Image.open(curr_img))\n",
    "        list(df[df[\"image\"] == curr_img][\"caption\"])\n",
    "        if self.transform is not None:\n",
    "            img_arr = self.transform(img_arr)\n",
    "        for idx, lbl in enumerate(curr_lbls):\n",
    "            curr_lbls[idx] = \"<SOS>\" + lbl\n",
    "        return img_arr, curr_lbls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5cbfd20a-7dc4-4d6a-8995-2c6fceaf640e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9608)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Resize((299, 299)),\n",
    "    # transforms.Normalize(mean=[0., 0.456, 0.406], std=[1,1,1]),\n",
    "])\n",
    "dataset  = Flicker8Dataset(\"Data/captions.csv\", \"Data/Images/\", transform=transform_pipeline)\n",
    "val = next(iter(dataset))\n",
    "val[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8923c1-926e-4a2d-85b9-5639503e663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/captions.csv') as f:\n",
    "    lines = f.readlines()\n",
    "lines = lines[1:]\n",
    "captions = {}\n",
    "for line in lines:\n",
    "    split_line = line.split(',')\n",
    "    file_name, caption= split_line[0], split_line[1]\n",
    "    caption = '<SOS>' + caption\n",
    "    if file_name in captions:\n",
    "        captions[file_name].append(caption)\n",
    "    else:\n",
    "        captions[file_name] = [caption]\n",
    "\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfedf1c3-75c0-4209-beb5-57e03cadb50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.vgg import VGG16_Weights\n",
    "img, captions = next(iter(dataset))\n",
    "input_img = img[None,:,:,:]\n",
    "vgg16 = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "features = vgg16(input_img)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49673a8f-4bbf-4bd0-9928-bc640b738c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.vgg import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6f80007-8b5f-467b-832b-4cba43e70702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 329, 500])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cd87f0a-a513-48d8-bf61-e6160787039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'VGG16_Weights'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7529bf-872e-4ddf-8234-ca6061885e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
