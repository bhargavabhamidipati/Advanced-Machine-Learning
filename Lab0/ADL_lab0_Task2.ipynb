{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e06a1a3-edc7-4d05-b72b-048f6b2a5b1f",
   "metadata": {},
   "source": [
    "# Group 12\n",
    "## Lab 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3c1d61-b346-4d06-8cf3-84b088031a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318c0d7-b835-4370-8828-23a97df27306",
   "metadata": {},
   "source": [
    "## 0.2 Task\n",
    "### 0.2.1 Transfer Learning from ImageNet  \n",
    "### Results  \n",
    "CIFAR-10 data with alexnet (Fine tuning): Accuracy 37.20%   \n",
    "CIFAR-10 data with alexnet (Feature extraction): Accuracy 76.10%t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15669171-e478-4324-a963-1e0ff4440f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return the best performing model after training\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    best_model = {}\n",
    "    val_prediction = None\n",
    "    train_prediction = None\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    train_accuracy = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    val_accuracies = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    val_loss_per_epoch = 0.0\n",
    "    train_loss_per_epoch = 0.0\n",
    "\n",
    "    # initialize the tensorboard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # tarin\n",
    "        model.train() # set model in taining mode\n",
    "        total_train_loss = 0.0\n",
    "        #for i, data in enumerate(train_loader):\n",
    "        #    inputs, label = data\n",
    "        for inputs, label in train_loader:\n",
    "        \n",
    "            # optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # model output\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # loss function\n",
    "            loss = criterion(outputs, label)\n",
    "\n",
    "            # back propogate\n",
    "            loss.backward()\n",
    "\n",
    "            # apply optimser, update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # accumulate the loss\n",
    "            total_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Prepare for calculating train accuracy\n",
    "            _, train_prediction = torch.max(outputs, 1)\n",
    "            train_total += label.size(0)\n",
    "            train_correct += (train_prediction == label).sum().item()\n",
    "            print(f'epoch: {epoch+1}, train_total: {train_total}')\n",
    "\n",
    "        # Calculate train accuracy\n",
    "        train_accuracy = train_correct/train_total\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # store all validaion losses for each epoch\n",
    "        train_loss_per_epoch = total_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss_per_epoch)\n",
    "        \n",
    "        # Log training loss to the tensorboard\n",
    "        writer.add_scalar('training_loss', train_loss_per_epoch, epoch)\n",
    "\n",
    "\n",
    "        # validate\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        total_val_loss = 0.0\n",
    "        for inputs, label in val_loader:\n",
    "            # apply model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # calulate loss\n",
    "            val_loss = criterion(outputs, label)\n",
    "\n",
    "            # when best model , save it\n",
    "            if val_loss < best_val_loss:\n",
    "                # save the model\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "                best_model = deepcopy(model.state_dict())\n",
    "\n",
    "            # accumulate loss\n",
    "            total_val_loss += val_loss.item() * inputs.size(0)\n",
    "\n",
    "            # Prepare for calculating validation accuracy\n",
    "            _, val_prediction = torch.max(outputs, 1)\n",
    "            val_total += label.size(0)\n",
    "            val_correct += (val_prediction == label).sum().item()\n",
    "            print(f'epoch: {epoch+1}, val_total: {val_total}')\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # store all validaion losses for each epoch\n",
    "        val_loss_per_epoch = total_val_loss/len(val_loader.dataset)\n",
    "        val_losses.append(val_loss_per_epoch)\n",
    "\n",
    "        # Log training loss to the tensorboard\n",
    "        writer.add_scalar('validation_loss', val_loss_per_epoch, epoch)\n",
    "\n",
    "        # Print training and validation loss for each epoch\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss_per_epoch:.4f}, Validation Loss: {val_loss_per_epoch:.4f}\")\n",
    "    \n",
    "    # calculate average accuracy \n",
    "    train_accuracy_final = sum(train_accuracies)/len(train_accuracies)\n",
    "    print(f'\\nTraining Accuracy : {train_accuracy_final * 100:.2f}% ')\n",
    "\n",
    "    val_accuracy_final = sum(val_accuracies)/len(val_accuracies)\n",
    "    print(f'\\nValidation Accuracy : {val_accuracy_final * 100:.2f}% ')\n",
    "    \n",
    "    #print (val_losses)\n",
    "    #print(num_epochs)\n",
    "    \"\"\"\n",
    "    # Plot\n",
    "    # 1. test and validation loss vs epoch\n",
    "    epochs_as_list = []\n",
    "    epochs_as_list = range(1,num_epochs + 1)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(epochs_as_list,val_losses,color='red',linestyle='-',label='Validation Loss')\n",
    "    plt.plot(epochs_as_list, train_losses, color='green', linestyle='-',label='Training Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Loss at each epoch')\n",
    "    plt.show()\n",
    "\n",
    "    # 2. test and validation accuracy vs epoch\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(epochs_as_list,val_accuracies,color='red',linestyle='-',label='Validation Accuracy')\n",
    "    plt.plot(epochs_as_list, train_accuracies, color='green', linestyle='-',label='Training Accuracy')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Accuracy at each epoch')\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    # Load the best model and return\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # close writer\n",
    "    writer.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    # test with test data on he tarined model\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_accuracy = 0.0\n",
    "    test_prediction = None\n",
    "    # initialize the tensorboard writer\n",
    "    writer_test = SummaryWriter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pre_list = []\n",
    "        labels_list = []\n",
    "        for inputs, label in test_loader:\n",
    "            # predict\n",
    "            outputs = model(inputs)\n",
    "            _, test_prediction = torch.max(outputs, 1)\n",
    "            # accuracy\n",
    "            test_correct += (test_prediction == label).sum().item()\n",
    "            test_total += label.size(0)\n",
    "            pre_list.extend(test_prediction.tolist())\n",
    "            labels_list.extend(label.tolist())\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    \"\"\"\n",
    "    conf_mat = confusion_matrix(pre_list, labels_list)\n",
    "    conf_mat_visualise = ConfusionMatrixDisplay(conf_mat, display_labels=['Anchor','Ant'])\n",
    "    #conf_mat_visualise.plot()\n",
    "    conf_mat_visualise.plot(colorbar=False)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Test accuracy\n",
    "    test_accuracy = test_correct / test_total\n",
    "    print(f'Test Accuracy {test_accuracy * 100:.2f}% ')\n",
    "    # Log test accuracy to the tensorboard\n",
    "    writer_test.add_scalar('Accuracy', test_accuracy)\n",
    "\n",
    "    # close writer\n",
    "    writer_test.close()\n",
    "    \n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5adcc7-195d-4939-be1e-6bb21a77483f",
   "metadata": {},
   "source": [
    "### \f\n",
    "Fine tuning using AlexNet model for CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a5dfdc-3434-4a31-ae17-dbd911cc0346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model_ft = models.alexnet(pretrained=True)\n",
    "\n",
    "# get the input features of the last layer\n",
    "in_last_layer = model_ft.classifier[6].in_features\n",
    "\n",
    "# add a output layer to the model\n",
    "model_ft.classifier[6] = nn.Linear(in_last_layer, 10)\n",
    "\n",
    "# Print input size\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267bfab9-0ffa-4882-b627-d01ed2ebe513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5521c6b1-f21d-4e47-b430-9a391f63cb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),      # Resize to 224x224, Alexnet expects inputs to be in this size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# load CIFAR10 data\n",
    "batch_size = 100 \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',train = True, download=True, transform = transform)\n",
    "\n",
    "\n",
    "# Since the test set has 50000 images, its quite large for training, hence just selecting a small subset (1000 images per class)\n",
    "# Choose a fixed number of samples per class\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_samples_per_class = 1000 \n",
    "expected_sample_cnt = len(classes) * num_samples_per_class\n",
    "#print(expected_sample_cnt)\n",
    "\n",
    "\n",
    "# Separate the data by class... Break the loop as soon as we have enough samples (as mentioned in num_samples_per_class ) per class\n",
    "continue_loop = 'j'\n",
    "class_data = [[] for _ in range(10)]\n",
    "for idx, (image, label) in enumerate(trainset):\n",
    "    if (continue_loop == 'j') and (len(class_data[label]) < num_samples_per_class):\n",
    "        class_data[label].append(idx)\n",
    "    \n",
    "    continue_loop = 'n'\n",
    "    for i in class_data:\n",
    "        if len(i) < num_samples_per_class:\n",
    "            continue_loop = 'j'\n",
    "            break\n",
    "\n",
    "    if continue_loop == 'n':\n",
    "        break\n",
    "    #print(f' {label} length = {len(class_data[label])}')\n",
    "\n",
    "\n",
    "\n",
    "# Select samples from each class\n",
    "selected_indices = []\n",
    "for data in class_data:\n",
    "    selected_indices.extend(np.random.choice(data, num_samples_per_class, replace=False))\n",
    "    #print(selected_indices)\n",
    "    if len(selected_indices) > expected_sample_cnt:\n",
    "        break\n",
    "\n",
    "# Create a training subset dataset with balanced classes\n",
    "trainset_subset = torch.utils.data.Subset(trainset, selected_indices)\n",
    "train_loader = torch.utils.data.DataLoader(trainset_subset,shuffle = True, batch_size = batch_size)\n",
    "\n",
    "# Load Test data\n",
    "testdata = torchvision.datasets.CIFAR10(root='./data',train = False,download = True, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9a2e7b-658c-4e47-aaac-5cf03d638a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test data into test set (1000 samples) and validation set (1000 samples)\n",
    "testset, valset, _ = torch.utils.data.random_split(testdata,[0.1, 0.1,0.8])\n",
    "test_loader = torch.utils.data.DataLoader(testset,shuffle = True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(valset,shuffle = True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608247e3-360c-47c5-8b39-bb76a5bec09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset_subset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b23c477-6d60-4e39-b5e7-747892c922f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_total: 100\n",
      "epoch: 1, train_total: 200\n",
      "epoch: 1, train_total: 300\n",
      "epoch: 1, train_total: 400\n",
      "epoch: 1, train_total: 500\n",
      "epoch: 1, train_total: 600\n",
      "epoch: 1, train_total: 700\n",
      "epoch: 1, train_total: 800\n",
      "epoch: 1, train_total: 900\n",
      "epoch: 1, train_total: 1000\n",
      "epoch: 1, train_total: 1100\n",
      "epoch: 1, train_total: 1200\n",
      "epoch: 1, train_total: 1300\n",
      "epoch: 1, train_total: 1400\n",
      "epoch: 1, train_total: 1500\n",
      "epoch: 1, train_total: 1600\n",
      "epoch: 1, train_total: 1700\n",
      "epoch: 1, train_total: 1800\n",
      "epoch: 1, train_total: 1900\n",
      "epoch: 1, train_total: 2000\n",
      "epoch: 1, train_total: 2100\n",
      "epoch: 1, train_total: 2200\n",
      "epoch: 1, train_total: 2300\n",
      "epoch: 1, train_total: 2400\n",
      "epoch: 1, train_total: 2500\n",
      "epoch: 1, train_total: 2600\n",
      "epoch: 1, train_total: 2700\n",
      "epoch: 1, train_total: 2800\n",
      "epoch: 1, train_total: 2900\n",
      "epoch: 1, train_total: 3000\n",
      "epoch: 1, train_total: 3100\n",
      "epoch: 1, train_total: 3200\n",
      "epoch: 1, train_total: 3300\n",
      "epoch: 1, train_total: 3400\n",
      "epoch: 1, train_total: 3500\n",
      "epoch: 1, train_total: 3600\n",
      "epoch: 1, train_total: 3700\n",
      "epoch: 1, train_total: 3800\n",
      "epoch: 1, train_total: 3900\n",
      "epoch: 1, train_total: 4000\n",
      "epoch: 1, train_total: 4100\n",
      "epoch: 1, train_total: 4200\n",
      "epoch: 1, train_total: 4300\n",
      "epoch: 1, train_total: 4400\n",
      "epoch: 1, train_total: 4500\n",
      "epoch: 1, train_total: 4600\n",
      "epoch: 1, train_total: 4700\n",
      "epoch: 1, train_total: 4800\n",
      "epoch: 1, train_total: 4900\n",
      "epoch: 1, train_total: 5000\n",
      "epoch: 1, train_total: 5100\n",
      "epoch: 1, train_total: 5200\n",
      "epoch: 1, train_total: 5300\n",
      "epoch: 1, train_total: 5400\n",
      "epoch: 1, train_total: 5500\n",
      "epoch: 1, train_total: 5600\n",
      "epoch: 1, train_total: 5700\n",
      "epoch: 1, train_total: 5800\n",
      "epoch: 1, train_total: 5900\n",
      "epoch: 1, train_total: 6000\n",
      "epoch: 1, train_total: 6100\n",
      "epoch: 1, train_total: 6200\n",
      "epoch: 1, train_total: 6300\n",
      "epoch: 1, train_total: 6400\n",
      "epoch: 1, train_total: 6500\n",
      "epoch: 1, train_total: 6600\n",
      "epoch: 1, train_total: 6700\n",
      "epoch: 1, train_total: 6800\n",
      "epoch: 1, train_total: 6900\n",
      "epoch: 1, train_total: 7000\n",
      "epoch: 1, train_total: 7100\n",
      "epoch: 1, train_total: 7200\n",
      "epoch: 1, train_total: 7300\n",
      "epoch: 1, train_total: 7400\n",
      "epoch: 1, train_total: 7500\n",
      "epoch: 1, train_total: 7600\n",
      "epoch: 1, train_total: 7700\n",
      "epoch: 1, train_total: 7800\n",
      "epoch: 1, train_total: 7900\n",
      "epoch: 1, train_total: 8000\n",
      "epoch: 1, train_total: 8100\n",
      "epoch: 1, train_total: 8200\n",
      "epoch: 1, train_total: 8300\n",
      "epoch: 1, train_total: 8400\n",
      "epoch: 1, train_total: 8500\n",
      "epoch: 1, train_total: 8600\n",
      "epoch: 1, train_total: 8700\n",
      "epoch: 1, train_total: 8800\n",
      "epoch: 1, train_total: 8900\n",
      "epoch: 1, train_total: 9000\n",
      "epoch: 1, train_total: 9100\n",
      "epoch: 1, train_total: 9200\n",
      "epoch: 1, train_total: 9300\n",
      "epoch: 1, train_total: 9400\n",
      "epoch: 1, train_total: 9500\n",
      "epoch: 1, train_total: 9600\n",
      "epoch: 1, train_total: 9700\n",
      "epoch: 1, train_total: 9800\n",
      "epoch: 1, train_total: 9900\n",
      "epoch: 1, train_total: 10000\n",
      "epoch: 1, val_total: 100\n",
      "epoch: 1, val_total: 200\n",
      "epoch: 1, val_total: 300\n",
      "epoch: 1, val_total: 400\n",
      "epoch: 1, val_total: 500\n",
      "epoch: 1, val_total: 600\n",
      "epoch: 1, val_total: 700\n",
      "epoch: 1, val_total: 800\n",
      "epoch: 1, val_total: 900\n",
      "epoch: 1, val_total: 1000\n",
      "Epoch 1/2, Training Loss: 2.1976, Validation Loss: 2.0087\n",
      "epoch: 2, train_total: 10100\n",
      "epoch: 2, train_total: 10200\n",
      "epoch: 2, train_total: 10300\n",
      "epoch: 2, train_total: 10400\n",
      "epoch: 2, train_total: 10500\n",
      "epoch: 2, train_total: 10600\n",
      "epoch: 2, train_total: 10700\n",
      "epoch: 2, train_total: 10800\n",
      "epoch: 2, train_total: 10900\n",
      "epoch: 2, train_total: 11000\n",
      "epoch: 2, train_total: 11100\n",
      "epoch: 2, train_total: 11200\n",
      "epoch: 2, train_total: 11300\n",
      "epoch: 2, train_total: 11400\n",
      "epoch: 2, train_total: 11500\n",
      "epoch: 2, train_total: 11600\n",
      "epoch: 2, train_total: 11700\n",
      "epoch: 2, train_total: 11800\n",
      "epoch: 2, train_total: 11900\n",
      "epoch: 2, train_total: 12000\n",
      "epoch: 2, train_total: 12100\n",
      "epoch: 2, train_total: 12200\n",
      "epoch: 2, train_total: 12300\n",
      "epoch: 2, train_total: 12400\n",
      "epoch: 2, train_total: 12500\n",
      "epoch: 2, train_total: 12600\n",
      "epoch: 2, train_total: 12700\n",
      "epoch: 2, train_total: 12800\n",
      "epoch: 2, train_total: 12900\n",
      "epoch: 2, train_total: 13000\n",
      "epoch: 2, train_total: 13100\n",
      "epoch: 2, train_total: 13200\n",
      "epoch: 2, train_total: 13300\n",
      "epoch: 2, train_total: 13400\n",
      "epoch: 2, train_total: 13500\n",
      "epoch: 2, train_total: 13600\n",
      "epoch: 2, train_total: 13700\n",
      "epoch: 2, train_total: 13800\n",
      "epoch: 2, train_total: 13900\n",
      "epoch: 2, train_total: 14000\n",
      "epoch: 2, train_total: 14100\n",
      "epoch: 2, train_total: 14200\n",
      "epoch: 2, train_total: 14300\n",
      "epoch: 2, train_total: 14400\n",
      "epoch: 2, train_total: 14500\n",
      "epoch: 2, train_total: 14600\n",
      "epoch: 2, train_total: 14700\n",
      "epoch: 2, train_total: 14800\n",
      "epoch: 2, train_total: 14900\n",
      "epoch: 2, train_total: 15000\n",
      "epoch: 2, train_total: 15100\n",
      "epoch: 2, train_total: 15200\n",
      "epoch: 2, train_total: 15300\n",
      "epoch: 2, train_total: 15400\n",
      "epoch: 2, train_total: 15500\n",
      "epoch: 2, train_total: 15600\n",
      "epoch: 2, train_total: 15700\n",
      "epoch: 2, train_total: 15800\n",
      "epoch: 2, train_total: 15900\n",
      "epoch: 2, train_total: 16000\n",
      "epoch: 2, train_total: 16100\n",
      "epoch: 2, train_total: 16200\n",
      "epoch: 2, train_total: 16300\n",
      "epoch: 2, train_total: 16400\n",
      "epoch: 2, train_total: 16500\n",
      "epoch: 2, train_total: 16600\n",
      "epoch: 2, train_total: 16700\n",
      "epoch: 2, train_total: 16800\n",
      "epoch: 2, train_total: 16900\n",
      "epoch: 2, train_total: 17000\n",
      "epoch: 2, train_total: 17100\n",
      "epoch: 2, train_total: 17200\n",
      "epoch: 2, train_total: 17300\n",
      "epoch: 2, train_total: 17400\n",
      "epoch: 2, train_total: 17500\n",
      "epoch: 2, train_total: 17600\n",
      "epoch: 2, train_total: 17700\n",
      "epoch: 2, train_total: 17800\n",
      "epoch: 2, train_total: 17900\n",
      "epoch: 2, train_total: 18000\n",
      "epoch: 2, train_total: 18100\n",
      "epoch: 2, train_total: 18200\n",
      "epoch: 2, train_total: 18300\n",
      "epoch: 2, train_total: 18400\n",
      "epoch: 2, train_total: 18500\n",
      "epoch: 2, train_total: 18600\n",
      "epoch: 2, train_total: 18700\n",
      "epoch: 2, train_total: 18800\n",
      "epoch: 2, train_total: 18900\n",
      "epoch: 2, train_total: 19000\n",
      "epoch: 2, train_total: 19100\n",
      "epoch: 2, train_total: 19200\n",
      "epoch: 2, train_total: 19300\n",
      "epoch: 2, train_total: 19400\n",
      "epoch: 2, train_total: 19500\n",
      "epoch: 2, train_total: 19600\n",
      "epoch: 2, train_total: 19700\n",
      "epoch: 2, train_total: 19800\n",
      "epoch: 2, train_total: 19900\n",
      "epoch: 2, train_total: 20000\n",
      "epoch: 2, val_total: 1100\n",
      "epoch: 2, val_total: 1200\n",
      "epoch: 2, val_total: 1300\n",
      "epoch: 2, val_total: 1400\n",
      "epoch: 2, val_total: 1500\n",
      "epoch: 2, val_total: 1600\n",
      "epoch: 2, val_total: 1700\n",
      "epoch: 2, val_total: 1800\n",
      "epoch: 2, val_total: 1900\n",
      "epoch: 2, val_total: 2000\n",
      "Epoch 2/2, Training Loss: 1.9102, Validation Loss: 1.7581\n",
      "\n",
      "Training Accuracy : 19.64% \n",
      "\n",
      "Validation Accuracy : 28.98% \n",
      "Test Accuracy 34.80% \n"
     ]
    }
   ],
   "source": [
    "# set the hyperparameters, loss function and criterion\n",
    "epochs_ft = 2\n",
    "LEARNING_RATE_ft = 0.001\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(),lr=LEARNING_RATE_ft)\n",
    "\n",
    "# Train the model\n",
    "trained_model_ft = train_model(model_ft, criterion_ft, optimizer_ft, train_loader, val_loader, epochs_ft)\n",
    "\n",
    "# Test the model\n",
    "tested_model = test_model(trained_model_ft,test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0616d63-b0f2-4944-87ee-030bb4c65ccf",
   "metadata": {},
   "source": [
    "### Feature extraction.\n",
    "\n",
    "Only the parameters of the final layer is allowed to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beca4671-e799-48ff-bbcd-70d8fdc5be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model_fe = models.alexnet(pretrained=True)\n",
    "\n",
    "# get the input features of the last layer\n",
    "in_last_layer = model_fe.classifier[6].in_features\n",
    "\n",
    "# add a output layer to the model\n",
    "model_fe.classifier[6] = nn.Linear(in_last_layer, 10)\n",
    "\n",
    "# Print input size\n",
    "#print(model_fe)\n",
    "\n",
    "# freeze the parameter update in all the layers\n",
    "for parameters in model_fe.parameters():\n",
    "    parameters.requires_grad = False\n",
    "\n",
    "# unfreeze the parameter update of the last layer\n",
    "model_fe.classifier[6].weight.requires_grad = True\n",
    "model_fe.classifier[6].bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f9aa9a-b7f1-4f29-a03b-6d169402394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_total: 100\n",
      "epoch: 1, train_total: 200\n",
      "epoch: 1, train_total: 300\n",
      "epoch: 1, train_total: 400\n",
      "epoch: 1, train_total: 500\n",
      "epoch: 1, train_total: 600\n",
      "epoch: 1, train_total: 700\n",
      "epoch: 1, train_total: 800\n",
      "epoch: 1, train_total: 900\n",
      "epoch: 1, train_total: 1000\n",
      "epoch: 1, train_total: 1100\n",
      "epoch: 1, train_total: 1200\n",
      "epoch: 1, train_total: 1300\n",
      "epoch: 1, train_total: 1400\n",
      "epoch: 1, train_total: 1500\n",
      "epoch: 1, train_total: 1600\n",
      "epoch: 1, train_total: 1700\n",
      "epoch: 1, train_total: 1800\n",
      "epoch: 1, train_total: 1900\n",
      "epoch: 1, train_total: 2000\n",
      "epoch: 1, train_total: 2100\n",
      "epoch: 1, train_total: 2200\n",
      "epoch: 1, train_total: 2300\n",
      "epoch: 1, train_total: 2400\n",
      "epoch: 1, train_total: 2500\n",
      "epoch: 1, train_total: 2600\n",
      "epoch: 1, train_total: 2700\n",
      "epoch: 1, train_total: 2800\n",
      "epoch: 1, train_total: 2900\n",
      "epoch: 1, train_total: 3000\n",
      "epoch: 1, train_total: 3100\n",
      "epoch: 1, train_total: 3200\n",
      "epoch: 1, train_total: 3300\n",
      "epoch: 1, train_total: 3400\n",
      "epoch: 1, train_total: 3500\n",
      "epoch: 1, train_total: 3600\n",
      "epoch: 1, train_total: 3700\n",
      "epoch: 1, train_total: 3800\n",
      "epoch: 1, train_total: 3900\n",
      "epoch: 1, train_total: 4000\n",
      "epoch: 1, train_total: 4100\n",
      "epoch: 1, train_total: 4200\n",
      "epoch: 1, train_total: 4300\n",
      "epoch: 1, train_total: 4400\n",
      "epoch: 1, train_total: 4500\n",
      "epoch: 1, train_total: 4600\n",
      "epoch: 1, train_total: 4700\n",
      "epoch: 1, train_total: 4800\n",
      "epoch: 1, train_total: 4900\n",
      "epoch: 1, train_total: 5000\n",
      "epoch: 1, train_total: 5100\n",
      "epoch: 1, train_total: 5200\n",
      "epoch: 1, train_total: 5300\n",
      "epoch: 1, train_total: 5400\n",
      "epoch: 1, train_total: 5500\n",
      "epoch: 1, train_total: 5600\n",
      "epoch: 1, train_total: 5700\n",
      "epoch: 1, train_total: 5800\n",
      "epoch: 1, train_total: 5900\n",
      "epoch: 1, train_total: 6000\n",
      "epoch: 1, train_total: 6100\n",
      "epoch: 1, train_total: 6200\n",
      "epoch: 1, train_total: 6300\n",
      "epoch: 1, train_total: 6400\n",
      "epoch: 1, train_total: 6500\n",
      "epoch: 1, train_total: 6600\n",
      "epoch: 1, train_total: 6700\n",
      "epoch: 1, train_total: 6800\n",
      "epoch: 1, train_total: 6900\n",
      "epoch: 1, train_total: 7000\n",
      "epoch: 1, train_total: 7100\n",
      "epoch: 1, train_total: 7200\n",
      "epoch: 1, train_total: 7300\n",
      "epoch: 1, train_total: 7400\n",
      "epoch: 1, train_total: 7500\n",
      "epoch: 1, train_total: 7600\n",
      "epoch: 1, train_total: 7700\n",
      "epoch: 1, train_total: 7800\n",
      "epoch: 1, train_total: 7900\n",
      "epoch: 1, train_total: 8000\n",
      "epoch: 1, train_total: 8100\n",
      "epoch: 1, train_total: 8200\n",
      "epoch: 1, train_total: 8300\n",
      "epoch: 1, train_total: 8400\n",
      "epoch: 1, train_total: 8500\n",
      "epoch: 1, train_total: 8600\n",
      "epoch: 1, train_total: 8700\n",
      "epoch: 1, train_total: 8800\n",
      "epoch: 1, train_total: 8900\n",
      "epoch: 1, train_total: 9000\n",
      "epoch: 1, train_total: 9100\n",
      "epoch: 1, train_total: 9200\n",
      "epoch: 1, train_total: 9300\n",
      "epoch: 1, train_total: 9400\n",
      "epoch: 1, train_total: 9500\n",
      "epoch: 1, train_total: 9600\n",
      "epoch: 1, train_total: 9700\n",
      "epoch: 1, train_total: 9800\n",
      "epoch: 1, train_total: 9900\n",
      "epoch: 1, train_total: 10000\n",
      "epoch: 1, val_total: 100\n",
      "epoch: 1, val_total: 200\n",
      "epoch: 1, val_total: 300\n",
      "epoch: 1, val_total: 400\n",
      "epoch: 1, val_total: 500\n",
      "epoch: 1, val_total: 600\n",
      "epoch: 1, val_total: 700\n",
      "epoch: 1, val_total: 800\n",
      "epoch: 1, val_total: 900\n",
      "epoch: 1, val_total: 1000\n",
      "Epoch 1/2, Training Loss: 1.0647, Validation Loss: 0.8262\n",
      "epoch: 2, train_total: 10100\n",
      "epoch: 2, train_total: 10200\n",
      "epoch: 2, train_total: 10300\n",
      "epoch: 2, train_total: 10400\n",
      "epoch: 2, train_total: 10500\n",
      "epoch: 2, train_total: 10600\n",
      "epoch: 2, train_total: 10700\n",
      "epoch: 2, train_total: 10800\n",
      "epoch: 2, train_total: 10900\n",
      "epoch: 2, train_total: 11000\n",
      "epoch: 2, train_total: 11100\n",
      "epoch: 2, train_total: 11200\n",
      "epoch: 2, train_total: 11300\n",
      "epoch: 2, train_total: 11400\n",
      "epoch: 2, train_total: 11500\n",
      "epoch: 2, train_total: 11600\n",
      "epoch: 2, train_total: 11700\n",
      "epoch: 2, train_total: 11800\n",
      "epoch: 2, train_total: 11900\n",
      "epoch: 2, train_total: 12000\n",
      "epoch: 2, train_total: 12100\n",
      "epoch: 2, train_total: 12200\n",
      "epoch: 2, train_total: 12300\n",
      "epoch: 2, train_total: 12400\n",
      "epoch: 2, train_total: 12500\n",
      "epoch: 2, train_total: 12600\n",
      "epoch: 2, train_total: 12700\n",
      "epoch: 2, train_total: 12800\n",
      "epoch: 2, train_total: 12900\n",
      "epoch: 2, train_total: 13000\n",
      "epoch: 2, train_total: 13100\n",
      "epoch: 2, train_total: 13200\n",
      "epoch: 2, train_total: 13300\n",
      "epoch: 2, train_total: 13400\n",
      "epoch: 2, train_total: 13500\n",
      "epoch: 2, train_total: 13600\n",
      "epoch: 2, train_total: 13700\n",
      "epoch: 2, train_total: 13800\n",
      "epoch: 2, train_total: 13900\n",
      "epoch: 2, train_total: 14000\n",
      "epoch: 2, train_total: 14100\n",
      "epoch: 2, train_total: 14200\n",
      "epoch: 2, train_total: 14300\n",
      "epoch: 2, train_total: 14400\n",
      "epoch: 2, train_total: 14500\n",
      "epoch: 2, train_total: 14600\n",
      "epoch: 2, train_total: 14700\n",
      "epoch: 2, train_total: 14800\n",
      "epoch: 2, train_total: 14900\n",
      "epoch: 2, train_total: 15000\n",
      "epoch: 2, train_total: 15100\n",
      "epoch: 2, train_total: 15200\n",
      "epoch: 2, train_total: 15300\n",
      "epoch: 2, train_total: 15400\n",
      "epoch: 2, train_total: 15500\n",
      "epoch: 2, train_total: 15600\n",
      "epoch: 2, train_total: 15700\n",
      "epoch: 2, train_total: 15800\n",
      "epoch: 2, train_total: 15900\n",
      "epoch: 2, train_total: 16000\n",
      "epoch: 2, train_total: 16100\n",
      "epoch: 2, train_total: 16200\n",
      "epoch: 2, train_total: 16300\n",
      "epoch: 2, train_total: 16400\n",
      "epoch: 2, train_total: 16500\n",
      "epoch: 2, train_total: 16600\n",
      "epoch: 2, train_total: 16700\n",
      "epoch: 2, train_total: 16800\n",
      "epoch: 2, train_total: 16900\n",
      "epoch: 2, train_total: 17000\n",
      "epoch: 2, train_total: 17100\n",
      "epoch: 2, train_total: 17200\n",
      "epoch: 2, train_total: 17300\n",
      "epoch: 2, train_total: 17400\n",
      "epoch: 2, train_total: 17500\n",
      "epoch: 2, train_total: 17600\n",
      "epoch: 2, train_total: 17700\n",
      "epoch: 2, train_total: 17800\n",
      "epoch: 2, train_total: 17900\n",
      "epoch: 2, train_total: 18000\n",
      "epoch: 2, train_total: 18100\n",
      "epoch: 2, train_total: 18200\n",
      "epoch: 2, train_total: 18300\n",
      "epoch: 2, train_total: 18400\n",
      "epoch: 2, train_total: 18500\n",
      "epoch: 2, train_total: 18600\n",
      "epoch: 2, train_total: 18700\n",
      "epoch: 2, train_total: 18800\n",
      "epoch: 2, train_total: 18900\n",
      "epoch: 2, train_total: 19000\n",
      "epoch: 2, train_total: 19100\n",
      "epoch: 2, train_total: 19200\n",
      "epoch: 2, train_total: 19300\n",
      "epoch: 2, train_total: 19400\n",
      "epoch: 2, train_total: 19500\n",
      "epoch: 2, train_total: 19600\n",
      "epoch: 2, train_total: 19700\n",
      "epoch: 2, train_total: 19800\n",
      "epoch: 2, train_total: 19900\n",
      "epoch: 2, train_total: 20000\n",
      "epoch: 2, val_total: 1100\n",
      "epoch: 2, val_total: 1200\n",
      "epoch: 2, val_total: 1300\n",
      "epoch: 2, val_total: 1400\n",
      "epoch: 2, val_total: 1500\n",
      "epoch: 2, val_total: 1600\n",
      "epoch: 2, val_total: 1700\n",
      "epoch: 2, val_total: 1800\n",
      "epoch: 2, val_total: 1900\n",
      "epoch: 2, val_total: 2000\n",
      "Epoch 2/2, Training Loss: 0.8207, Validation Loss: 0.7908\n",
      "\n",
      "Training Accuracy : 64.92% \n",
      "\n",
      "Validation Accuracy : 71.00% \n",
      "Test Accuracy 73.50% \n"
     ]
    }
   ],
   "source": [
    "# set the hyperparameters, loss function and criterion\n",
    "epochs_fe = 2\n",
    "LEARNING_RATE_fe = 0.001\n",
    "criterion_fe = nn.CrossEntropyLoss()\n",
    "optimizer_fe = torch.optim.Adam(model_fe.parameters(),lr=LEARNING_RATE_fe)\n",
    "\n",
    "# Train the model\n",
    "trained_model_fe = train_model(model_fe, criterion_fe, optimizer_fe, train_loader, val_loader, epochs_fe)\n",
    "\n",
    "# Test the model\n",
    "tested_model = test_model(trained_model_fe,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955a22c-01d1-4561-809f-8b12c1eaba3a",
   "metadata": {},
   "source": [
    "## 0.2.2 Transfer Learning from MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d73fe-ea6a-4960-834c-d8ea89440c6d",
   "metadata": {},
   "source": [
    "### Prepare a CNN of your choice and train it on the MNIST data. Report the accuracy\n",
    "\n",
    "Accuracy 93.50% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cceaa19-abdc-40ee-bb03-2ef5f496d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolution neural network for 1 channel images\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net_1Channel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define convolutional layer 1\n",
    "        self.conv1 = nn.Conv2d(1,6,3) # 1 input channels, 6 output channels, 3x3 kernel size\n",
    "        \n",
    "        # Define pooling layer\n",
    "        self.pool = nn.MaxPool2d(2,2) # 2x2 max pooling with a stride of 2\n",
    "        \n",
    "        # Define convolutional layer 1\n",
    "        self.conv2 = nn.Conv2d(6,16,3)  # 6 input channels, 16 output channels, 3x3 kernel size\n",
    "\n",
    "        # Define fully connected layers\n",
    "        \"\"\"\n",
    "        The input image size is 28x28 for MNIST.\n",
    "        After the first convolutional layer (conv1) with a 3x3 kernel and no padding, the spatial dimensions will be reduced to 26x26 (assuming stride = 1).\n",
    "        After the max pooling layer (pool) with a 2x2 kernel and stride of 2, the spatial dimensions will be reduced to 13x13.\n",
    "        After the second convolutional layer (conv2) with a 3x3 kernel and no padding, the spatial dimensions will be reduced to 11x11.\n",
    "        After the second max pooling layer (pool) with a 2x2 kernel and stride of 2, the spatial dimensions will be reduced to 5x5.\n",
    "        Therefore, the input size for the first fully connected layer (fc1) should be 16 * 5 * 5:\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 16*5*5 input features, 120 output features.. Input must be calulcated carefully based on the o/p of conv2\n",
    "        self.fc2 = nn.Linear(120, 84) # 120 input features, 84 output features\n",
    "        self.fc3 = nn.Linear(84, 10)  # 84 input features, 10 output features\n",
    "\n",
    "    \"\"\"\n",
    "        # Define Leaky ReLU activation function\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "\n",
    "    def test(self, x):\n",
    "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1) # flatten all dimensions except batch\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff622f1-2aa4-4e7e-8d33-f2171da05ecd",
   "metadata": {},
   "source": [
    "### Download the data, preprocess it and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a40c4d99-5662-4749-87b2-356d6d089bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Load the trainset\n",
    "trainset = torchvision.datasets.MNIST(root='./data',train = True, download=True, transform = transform)\n",
    "\n",
    "# Since the test set has 60000 images, its quite large for training, hence just selecting a small subset (1000 images per class)\n",
    "# Choose a fixed number of samples per class\n",
    "classes = ('0', '1', '2', '3','4', '5', '6', '7', '8', '9')\n",
    "num_samples_per_class = 1000 \n",
    "expected_sample_cnt = len(classes) * num_samples_per_class\n",
    "#print(expected_sample_cnt)\n",
    "\n",
    "\n",
    "# Separate the data by class... Break the loop as soon as we have enough samples (as mentioned in num_samples_per_class ) per class\n",
    "continue_loop = 'j'\n",
    "class_data = [[] for _ in range(len(classes))]\n",
    "for idx, (image, label) in enumerate(trainset):\n",
    "    if (continue_loop == 'j') and (len(class_data[label]) < num_samples_per_class):\n",
    "        class_data[label].append(idx)\n",
    "    \n",
    "    continue_loop = 'n'\n",
    "    for i in class_data:\n",
    "        if len(i) < num_samples_per_class:\n",
    "            continue_loop = 'j'\n",
    "            break\n",
    "\n",
    "    if continue_loop == 'n':\n",
    "        break\n",
    "    #print(f' {label} length = {len(class_data[label])}')\n",
    "\n",
    "\n",
    "\n",
    "# Select samples from each class\n",
    "selected_indices = []\n",
    "for data in class_data:\n",
    "    selected_indices.extend(np.random.choice(data, num_samples_per_class, replace=False))\n",
    "    #print(selected_indices)\n",
    "    if len(selected_indices) > expected_sample_cnt:\n",
    "        break\n",
    "\n",
    "# Create a subset dataset with balanced classes and used to create train loader\n",
    "trainset_subset = torch.utils.data.Subset(trainset, selected_indices)\n",
    "train_loader = torch.utils.data.DataLoader(trainset_subset,shuffle = True, batch_size = batch_size)\n",
    "\n",
    "# download test data\n",
    "testdata = torchvision.datasets.MNIST(root='./data',train = False,download = True, transform = transform)\n",
    "\n",
    "# Split the test data in test set (1000 samples) and validation set(1000 samples)\n",
    "testset, valset, _ = torch.utils.data.random_split(testdata,[0.1, 0.1,0.8])\n",
    "test_loader = torch.utils.data.DataLoader(testset,shuffle = True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(valset,shuffle = True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a1926f-1f11-4427-88ee-e7ce26b99fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset_subset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d1491-2795-4ee8-9d8b-e07d0c52acfc",
   "metadata": {},
   "source": [
    "### Train the CNN model on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "348cc758-9d2b-4040-8210-238a2e816571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_total: 64\n",
      "epoch: 1, train_total: 128\n",
      "epoch: 1, train_total: 192\n",
      "epoch: 1, train_total: 256\n",
      "epoch: 1, train_total: 320\n",
      "epoch: 1, train_total: 384\n",
      "epoch: 1, train_total: 448\n",
      "epoch: 1, train_total: 512\n",
      "epoch: 1, train_total: 576\n",
      "epoch: 1, train_total: 640\n",
      "epoch: 1, train_total: 704\n",
      "epoch: 1, train_total: 768\n",
      "epoch: 1, train_total: 832\n",
      "epoch: 1, train_total: 896\n",
      "epoch: 1, train_total: 960\n",
      "epoch: 1, train_total: 1024\n",
      "epoch: 1, train_total: 1088\n",
      "epoch: 1, train_total: 1152\n",
      "epoch: 1, train_total: 1216\n",
      "epoch: 1, train_total: 1280\n",
      "epoch: 1, train_total: 1344\n",
      "epoch: 1, train_total: 1408\n",
      "epoch: 1, train_total: 1472\n",
      "epoch: 1, train_total: 1536\n",
      "epoch: 1, train_total: 1600\n",
      "epoch: 1, train_total: 1664\n",
      "epoch: 1, train_total: 1728\n",
      "epoch: 1, train_total: 1792\n",
      "epoch: 1, train_total: 1856\n",
      "epoch: 1, train_total: 1920\n",
      "epoch: 1, train_total: 1984\n",
      "epoch: 1, train_total: 2048\n",
      "epoch: 1, train_total: 2112\n",
      "epoch: 1, train_total: 2176\n",
      "epoch: 1, train_total: 2240\n",
      "epoch: 1, train_total: 2304\n",
      "epoch: 1, train_total: 2368\n",
      "epoch: 1, train_total: 2432\n",
      "epoch: 1, train_total: 2496\n",
      "epoch: 1, train_total: 2560\n",
      "epoch: 1, train_total: 2624\n",
      "epoch: 1, train_total: 2688\n",
      "epoch: 1, train_total: 2752\n",
      "epoch: 1, train_total: 2816\n",
      "epoch: 1, train_total: 2880\n",
      "epoch: 1, train_total: 2944\n",
      "epoch: 1, train_total: 3008\n",
      "epoch: 1, train_total: 3072\n",
      "epoch: 1, train_total: 3136\n",
      "epoch: 1, train_total: 3200\n",
      "epoch: 1, train_total: 3264\n",
      "epoch: 1, train_total: 3328\n",
      "epoch: 1, train_total: 3392\n",
      "epoch: 1, train_total: 3456\n",
      "epoch: 1, train_total: 3520\n",
      "epoch: 1, train_total: 3584\n",
      "epoch: 1, train_total: 3648\n",
      "epoch: 1, train_total: 3712\n",
      "epoch: 1, train_total: 3776\n",
      "epoch: 1, train_total: 3840\n",
      "epoch: 1, train_total: 3904\n",
      "epoch: 1, train_total: 3968\n",
      "epoch: 1, train_total: 4032\n",
      "epoch: 1, train_total: 4096\n",
      "epoch: 1, train_total: 4160\n",
      "epoch: 1, train_total: 4224\n",
      "epoch: 1, train_total: 4288\n",
      "epoch: 1, train_total: 4352\n",
      "epoch: 1, train_total: 4416\n",
      "epoch: 1, train_total: 4480\n",
      "epoch: 1, train_total: 4544\n",
      "epoch: 1, train_total: 4608\n",
      "epoch: 1, train_total: 4672\n",
      "epoch: 1, train_total: 4736\n",
      "epoch: 1, train_total: 4800\n",
      "epoch: 1, train_total: 4864\n",
      "epoch: 1, train_total: 4928\n",
      "epoch: 1, train_total: 4992\n",
      "epoch: 1, train_total: 5056\n",
      "epoch: 1, train_total: 5120\n",
      "epoch: 1, train_total: 5184\n",
      "epoch: 1, train_total: 5248\n",
      "epoch: 1, train_total: 5312\n",
      "epoch: 1, train_total: 5376\n",
      "epoch: 1, train_total: 5440\n",
      "epoch: 1, train_total: 5504\n",
      "epoch: 1, train_total: 5568\n",
      "epoch: 1, train_total: 5632\n",
      "epoch: 1, train_total: 5696\n",
      "epoch: 1, train_total: 5760\n",
      "epoch: 1, train_total: 5824\n",
      "epoch: 1, train_total: 5888\n",
      "epoch: 1, train_total: 5952\n",
      "epoch: 1, train_total: 6016\n",
      "epoch: 1, train_total: 6080\n",
      "epoch: 1, train_total: 6144\n",
      "epoch: 1, train_total: 6208\n",
      "epoch: 1, train_total: 6272\n",
      "epoch: 1, train_total: 6336\n",
      "epoch: 1, train_total: 6400\n",
      "epoch: 1, train_total: 6464\n",
      "epoch: 1, train_total: 6528\n",
      "epoch: 1, train_total: 6592\n",
      "epoch: 1, train_total: 6656\n",
      "epoch: 1, train_total: 6720\n",
      "epoch: 1, train_total: 6784\n",
      "epoch: 1, train_total: 6848\n",
      "epoch: 1, train_total: 6912\n",
      "epoch: 1, train_total: 6976\n",
      "epoch: 1, train_total: 7040\n",
      "epoch: 1, train_total: 7104\n",
      "epoch: 1, train_total: 7168\n",
      "epoch: 1, train_total: 7232\n",
      "epoch: 1, train_total: 7296\n",
      "epoch: 1, train_total: 7360\n",
      "epoch: 1, train_total: 7424\n",
      "epoch: 1, train_total: 7488\n",
      "epoch: 1, train_total: 7552\n",
      "epoch: 1, train_total: 7616\n",
      "epoch: 1, train_total: 7680\n",
      "epoch: 1, train_total: 7744\n",
      "epoch: 1, train_total: 7808\n",
      "epoch: 1, train_total: 7872\n",
      "epoch: 1, train_total: 7936\n",
      "epoch: 1, train_total: 8000\n",
      "epoch: 1, train_total: 8064\n",
      "epoch: 1, train_total: 8128\n",
      "epoch: 1, train_total: 8192\n",
      "epoch: 1, train_total: 8256\n",
      "epoch: 1, train_total: 8320\n",
      "epoch: 1, train_total: 8384\n",
      "epoch: 1, train_total: 8448\n",
      "epoch: 1, train_total: 8512\n",
      "epoch: 1, train_total: 8576\n",
      "epoch: 1, train_total: 8640\n",
      "epoch: 1, train_total: 8704\n",
      "epoch: 1, train_total: 8768\n",
      "epoch: 1, train_total: 8832\n",
      "epoch: 1, train_total: 8896\n",
      "epoch: 1, train_total: 8960\n",
      "epoch: 1, train_total: 9024\n",
      "epoch: 1, train_total: 9088\n",
      "epoch: 1, train_total: 9152\n",
      "epoch: 1, train_total: 9216\n",
      "epoch: 1, train_total: 9280\n",
      "epoch: 1, train_total: 9344\n",
      "epoch: 1, train_total: 9408\n",
      "epoch: 1, train_total: 9472\n",
      "epoch: 1, train_total: 9536\n",
      "epoch: 1, train_total: 9600\n",
      "epoch: 1, train_total: 9664\n",
      "epoch: 1, train_total: 9728\n",
      "epoch: 1, train_total: 9792\n",
      "epoch: 1, train_total: 9856\n",
      "epoch: 1, train_total: 9920\n",
      "epoch: 1, train_total: 9984\n",
      "epoch: 1, train_total: 10000\n",
      "epoch: 1, val_total: 64\n",
      "epoch: 1, val_total: 128\n",
      "epoch: 1, val_total: 192\n",
      "epoch: 1, val_total: 256\n",
      "epoch: 1, val_total: 320\n",
      "epoch: 1, val_total: 384\n",
      "epoch: 1, val_total: 448\n",
      "epoch: 1, val_total: 512\n",
      "epoch: 1, val_total: 576\n",
      "epoch: 1, val_total: 640\n",
      "epoch: 1, val_total: 704\n",
      "epoch: 1, val_total: 768\n",
      "epoch: 1, val_total: 832\n",
      "epoch: 1, val_total: 896\n",
      "epoch: 1, val_total: 960\n",
      "epoch: 1, val_total: 1000\n",
      "Epoch 1/2, Training Loss: 0.8501, Validation Loss: 0.2987\n",
      "epoch: 2, train_total: 10064\n",
      "epoch: 2, train_total: 10128\n",
      "epoch: 2, train_total: 10192\n",
      "epoch: 2, train_total: 10256\n",
      "epoch: 2, train_total: 10320\n",
      "epoch: 2, train_total: 10384\n",
      "epoch: 2, train_total: 10448\n",
      "epoch: 2, train_total: 10512\n",
      "epoch: 2, train_total: 10576\n",
      "epoch: 2, train_total: 10640\n",
      "epoch: 2, train_total: 10704\n",
      "epoch: 2, train_total: 10768\n",
      "epoch: 2, train_total: 10832\n",
      "epoch: 2, train_total: 10896\n",
      "epoch: 2, train_total: 10960\n",
      "epoch: 2, train_total: 11024\n",
      "epoch: 2, train_total: 11088\n",
      "epoch: 2, train_total: 11152\n",
      "epoch: 2, train_total: 11216\n",
      "epoch: 2, train_total: 11280\n",
      "epoch: 2, train_total: 11344\n",
      "epoch: 2, train_total: 11408\n",
      "epoch: 2, train_total: 11472\n",
      "epoch: 2, train_total: 11536\n",
      "epoch: 2, train_total: 11600\n",
      "epoch: 2, train_total: 11664\n",
      "epoch: 2, train_total: 11728\n",
      "epoch: 2, train_total: 11792\n",
      "epoch: 2, train_total: 11856\n",
      "epoch: 2, train_total: 11920\n",
      "epoch: 2, train_total: 11984\n",
      "epoch: 2, train_total: 12048\n",
      "epoch: 2, train_total: 12112\n",
      "epoch: 2, train_total: 12176\n",
      "epoch: 2, train_total: 12240\n",
      "epoch: 2, train_total: 12304\n",
      "epoch: 2, train_total: 12368\n",
      "epoch: 2, train_total: 12432\n",
      "epoch: 2, train_total: 12496\n",
      "epoch: 2, train_total: 12560\n",
      "epoch: 2, train_total: 12624\n",
      "epoch: 2, train_total: 12688\n",
      "epoch: 2, train_total: 12752\n",
      "epoch: 2, train_total: 12816\n",
      "epoch: 2, train_total: 12880\n",
      "epoch: 2, train_total: 12944\n",
      "epoch: 2, train_total: 13008\n",
      "epoch: 2, train_total: 13072\n",
      "epoch: 2, train_total: 13136\n",
      "epoch: 2, train_total: 13200\n",
      "epoch: 2, train_total: 13264\n",
      "epoch: 2, train_total: 13328\n",
      "epoch: 2, train_total: 13392\n",
      "epoch: 2, train_total: 13456\n",
      "epoch: 2, train_total: 13520\n",
      "epoch: 2, train_total: 13584\n",
      "epoch: 2, train_total: 13648\n",
      "epoch: 2, train_total: 13712\n",
      "epoch: 2, train_total: 13776\n",
      "epoch: 2, train_total: 13840\n",
      "epoch: 2, train_total: 13904\n",
      "epoch: 2, train_total: 13968\n",
      "epoch: 2, train_total: 14032\n",
      "epoch: 2, train_total: 14096\n",
      "epoch: 2, train_total: 14160\n",
      "epoch: 2, train_total: 14224\n",
      "epoch: 2, train_total: 14288\n",
      "epoch: 2, train_total: 14352\n",
      "epoch: 2, train_total: 14416\n",
      "epoch: 2, train_total: 14480\n",
      "epoch: 2, train_total: 14544\n",
      "epoch: 2, train_total: 14608\n",
      "epoch: 2, train_total: 14672\n",
      "epoch: 2, train_total: 14736\n",
      "epoch: 2, train_total: 14800\n",
      "epoch: 2, train_total: 14864\n",
      "epoch: 2, train_total: 14928\n",
      "epoch: 2, train_total: 14992\n",
      "epoch: 2, train_total: 15056\n",
      "epoch: 2, train_total: 15120\n",
      "epoch: 2, train_total: 15184\n",
      "epoch: 2, train_total: 15248\n",
      "epoch: 2, train_total: 15312\n",
      "epoch: 2, train_total: 15376\n",
      "epoch: 2, train_total: 15440\n",
      "epoch: 2, train_total: 15504\n",
      "epoch: 2, train_total: 15568\n",
      "epoch: 2, train_total: 15632\n",
      "epoch: 2, train_total: 15696\n",
      "epoch: 2, train_total: 15760\n",
      "epoch: 2, train_total: 15824\n",
      "epoch: 2, train_total: 15888\n",
      "epoch: 2, train_total: 15952\n",
      "epoch: 2, train_total: 16016\n",
      "epoch: 2, train_total: 16080\n",
      "epoch: 2, train_total: 16144\n",
      "epoch: 2, train_total: 16208\n",
      "epoch: 2, train_total: 16272\n",
      "epoch: 2, train_total: 16336\n",
      "epoch: 2, train_total: 16400\n",
      "epoch: 2, train_total: 16464\n",
      "epoch: 2, train_total: 16528\n",
      "epoch: 2, train_total: 16592\n",
      "epoch: 2, train_total: 16656\n",
      "epoch: 2, train_total: 16720\n",
      "epoch: 2, train_total: 16784\n",
      "epoch: 2, train_total: 16848\n",
      "epoch: 2, train_total: 16912\n",
      "epoch: 2, train_total: 16976\n",
      "epoch: 2, train_total: 17040\n",
      "epoch: 2, train_total: 17104\n",
      "epoch: 2, train_total: 17168\n",
      "epoch: 2, train_total: 17232\n",
      "epoch: 2, train_total: 17296\n",
      "epoch: 2, train_total: 17360\n",
      "epoch: 2, train_total: 17424\n",
      "epoch: 2, train_total: 17488\n",
      "epoch: 2, train_total: 17552\n",
      "epoch: 2, train_total: 17616\n",
      "epoch: 2, train_total: 17680\n",
      "epoch: 2, train_total: 17744\n",
      "epoch: 2, train_total: 17808\n",
      "epoch: 2, train_total: 17872\n",
      "epoch: 2, train_total: 17936\n",
      "epoch: 2, train_total: 18000\n",
      "epoch: 2, train_total: 18064\n",
      "epoch: 2, train_total: 18128\n",
      "epoch: 2, train_total: 18192\n",
      "epoch: 2, train_total: 18256\n",
      "epoch: 2, train_total: 18320\n",
      "epoch: 2, train_total: 18384\n",
      "epoch: 2, train_total: 18448\n",
      "epoch: 2, train_total: 18512\n",
      "epoch: 2, train_total: 18576\n",
      "epoch: 2, train_total: 18640\n",
      "epoch: 2, train_total: 18704\n",
      "epoch: 2, train_total: 18768\n",
      "epoch: 2, train_total: 18832\n",
      "epoch: 2, train_total: 18896\n",
      "epoch: 2, train_total: 18960\n",
      "epoch: 2, train_total: 19024\n",
      "epoch: 2, train_total: 19088\n",
      "epoch: 2, train_total: 19152\n",
      "epoch: 2, train_total: 19216\n",
      "epoch: 2, train_total: 19280\n",
      "epoch: 2, train_total: 19344\n",
      "epoch: 2, train_total: 19408\n",
      "epoch: 2, train_total: 19472\n",
      "epoch: 2, train_total: 19536\n",
      "epoch: 2, train_total: 19600\n",
      "epoch: 2, train_total: 19664\n",
      "epoch: 2, train_total: 19728\n",
      "epoch: 2, train_total: 19792\n",
      "epoch: 2, train_total: 19856\n",
      "epoch: 2, train_total: 19920\n",
      "epoch: 2, train_total: 19984\n",
      "epoch: 2, train_total: 20000\n",
      "epoch: 2, val_total: 1064\n",
      "epoch: 2, val_total: 1128\n",
      "epoch: 2, val_total: 1192\n",
      "epoch: 2, val_total: 1256\n",
      "epoch: 2, val_total: 1320\n",
      "epoch: 2, val_total: 1384\n",
      "epoch: 2, val_total: 1448\n",
      "epoch: 2, val_total: 1512\n",
      "epoch: 2, val_total: 1576\n",
      "epoch: 2, val_total: 1640\n",
      "epoch: 2, val_total: 1704\n",
      "epoch: 2, val_total: 1768\n",
      "epoch: 2, val_total: 1832\n",
      "epoch: 2, val_total: 1896\n",
      "epoch: 2, val_total: 1960\n",
      "epoch: 2, val_total: 2000\n",
      "Epoch 2/2, Training Loss: 0.2276, Validation Loss: 0.1565\n",
      "\n",
      "Training Accuracy : 80.44% \n",
      "\n",
      "Validation Accuracy : 91.62% \n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_cnn_mnist = Net_1Channel()\n",
    "\n",
    "# Set optimiser and loss function\n",
    "optimizer_cnn_mnist = optim.Adam(model_cnn_mnist.parameters(),lr=0.001)\n",
    "criterion_cnn_mnist = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the number of epochs. Used a smal number as it takes a lot of training time.\n",
    "epochs_cnn_mnist = 2\n",
    "\n",
    "# # Train the model\n",
    "trained_model_cnn_mnist = train_model(model_cnn_mnist, criterion_cnn_mnist, optimizer_cnn_mnist, train_loader, val_loader, epochs_cnn_mnist)\n",
    "\n",
    "# save the trained best model\n",
    "PATH = './mnist_net_cnn.pth'\n",
    "torch.save(trained_model_cnn_mnist.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d80093-9630-4097-bc72-b36815428059",
   "metadata": {},
   "source": [
    "### Test the CNN model on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdee60a0-9c69-4af8-83fd-ab06c5bf5538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 94.60% \n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "PATH = './mnist_net_cnn.pth'\n",
    "trained_model_cnn_mnist.load_state_dict(torch.load(PATH))\n",
    "tested_model = test_model(trained_model_cnn_mnist,test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143dcf1-d7a3-4d5f-9559-c3a92ecfbf83",
   "metadata": {},
   "source": [
    "## Use the above model as a pre-trained CNN for the SVHN dataset. Report the accuracy\n",
    "\n",
    "Test Accuracy 70.31% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb37ed-f402-4dda-b77a-2f915e8eaa2c",
   "metadata": {},
   "source": [
    "### Download the data, preprocess it and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08945ceb-8469-464a-b7c7-9e64b96e55fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # The earier model was trained on MNIST data which was 1 channel gray scale and SVHN is 3 channel rgb so had to convert rgb to gray\n",
    "    transforms.Resize((28, 28)), # Mnist was 28 * 28 so earlier trained model expects input 28 * 28\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,)) # as its gray scale we need to normalise only 1 channel\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Load SVHN data\n",
    "trainset = torchvision.datasets.SVHN(root='./data',split = 'train', download=True, transform = transform)\n",
    "\n",
    "# Since the test set has 600000 images, its quite large for training, hence just selecting a small subset (1000 images per class)\n",
    "# Choose a fixed number of samples per class\n",
    "classes = ('1', '2', '3','4', '5', '6', '7', '8', '9','10')\n",
    "num_samples_per_class = 1000 \n",
    "expected_sample_cnt = len(classes) * num_samples_per_class\n",
    "#print(expected_sample_cnt)\n",
    "\n",
    "\n",
    "# Separate the data by class... Break the loop as soon as we have enough samples (as mentioned in num_samples_per_class ) per class\n",
    "continue_loop = 'j'\n",
    "class_data = [[] for _ in range(len(classes))]\n",
    "for idx, (image, label) in enumerate(trainset):\n",
    "    if (continue_loop == 'j') and (len(class_data[label]) < num_samples_per_class):\n",
    "        class_data[label].append(idx)\n",
    "    \n",
    "    continue_loop = 'n'\n",
    "    for i in class_data:\n",
    "        if len(i) < num_samples_per_class:\n",
    "            continue_loop = 'j'\n",
    "            break\n",
    "\n",
    "    if continue_loop == 'n':\n",
    "        break\n",
    "    #print(f' {label} length = {len(class_data[label])}')\n",
    "\n",
    "\n",
    "\n",
    "# Select samples from each class\n",
    "selected_indices = []\n",
    "for data in class_data:\n",
    "    selected_indices.extend(np.random.choice(data, num_samples_per_class, replace=False))\n",
    "    #print(selected_indices)\n",
    "    if len(selected_indices) > expected_sample_cnt:\n",
    "        break\n",
    "\n",
    "# Create a subset of train dataset with balanced classes and use it to create train loader\n",
    "trainset_subset = torch.utils.data.Subset(trainset, selected_indices)\n",
    "train_loader = torch.utils.data.DataLoader(trainset_subset,shuffle = True, batch_size = batch_size)\n",
    "\n",
    "# download test data\n",
    "testdata = torchvision.datasets.SVHN(root='./data',split = 'test',download = True, transform = transform)\n",
    "\n",
    "# Split test data into testset (2604 samples) and validation set (2604 samples)\n",
    "testset, valset, _ = torch.utils.data.random_split(testdata,[0.1, 0.1,0.8])\n",
    "test_loader = torch.utils.data.DataLoader(testset,shuffle = True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(valset,shuffle = True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf0bcc14-a4ff-44d3-bbb7-3657134ae45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "2604\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset_subset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da48b14e-94bf-4841-95fc-b82983e16a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_total: 64\n",
      "epoch: 1, train_total: 128\n",
      "epoch: 1, train_total: 192\n",
      "epoch: 1, train_total: 256\n",
      "epoch: 1, train_total: 320\n",
      "epoch: 1, train_total: 384\n",
      "epoch: 1, train_total: 448\n",
      "epoch: 1, train_total: 512\n",
      "epoch: 1, train_total: 576\n",
      "epoch: 1, train_total: 640\n",
      "epoch: 1, train_total: 704\n",
      "epoch: 1, train_total: 768\n",
      "epoch: 1, train_total: 832\n",
      "epoch: 1, train_total: 896\n",
      "epoch: 1, train_total: 960\n",
      "epoch: 1, train_total: 1024\n",
      "epoch: 1, train_total: 1088\n",
      "epoch: 1, train_total: 1152\n",
      "epoch: 1, train_total: 1216\n",
      "epoch: 1, train_total: 1280\n",
      "epoch: 1, train_total: 1344\n",
      "epoch: 1, train_total: 1408\n",
      "epoch: 1, train_total: 1472\n",
      "epoch: 1, train_total: 1536\n",
      "epoch: 1, train_total: 1600\n",
      "epoch: 1, train_total: 1664\n",
      "epoch: 1, train_total: 1728\n",
      "epoch: 1, train_total: 1792\n",
      "epoch: 1, train_total: 1856\n",
      "epoch: 1, train_total: 1920\n",
      "epoch: 1, train_total: 1984\n",
      "epoch: 1, train_total: 2048\n",
      "epoch: 1, train_total: 2112\n",
      "epoch: 1, train_total: 2176\n",
      "epoch: 1, train_total: 2240\n",
      "epoch: 1, train_total: 2304\n",
      "epoch: 1, train_total: 2368\n",
      "epoch: 1, train_total: 2432\n",
      "epoch: 1, train_total: 2496\n",
      "epoch: 1, train_total: 2560\n",
      "epoch: 1, train_total: 2624\n",
      "epoch: 1, train_total: 2688\n",
      "epoch: 1, train_total: 2752\n",
      "epoch: 1, train_total: 2816\n",
      "epoch: 1, train_total: 2880\n",
      "epoch: 1, train_total: 2944\n",
      "epoch: 1, train_total: 3008\n",
      "epoch: 1, train_total: 3072\n",
      "epoch: 1, train_total: 3136\n",
      "epoch: 1, train_total: 3200\n",
      "epoch: 1, train_total: 3264\n",
      "epoch: 1, train_total: 3328\n",
      "epoch: 1, train_total: 3392\n",
      "epoch: 1, train_total: 3456\n",
      "epoch: 1, train_total: 3520\n",
      "epoch: 1, train_total: 3584\n",
      "epoch: 1, train_total: 3648\n",
      "epoch: 1, train_total: 3712\n",
      "epoch: 1, train_total: 3776\n",
      "epoch: 1, train_total: 3840\n",
      "epoch: 1, train_total: 3904\n",
      "epoch: 1, train_total: 3968\n",
      "epoch: 1, train_total: 4032\n",
      "epoch: 1, train_total: 4096\n",
      "epoch: 1, train_total: 4160\n",
      "epoch: 1, train_total: 4224\n",
      "epoch: 1, train_total: 4288\n",
      "epoch: 1, train_total: 4352\n",
      "epoch: 1, train_total: 4416\n",
      "epoch: 1, train_total: 4480\n",
      "epoch: 1, train_total: 4544\n",
      "epoch: 1, train_total: 4608\n",
      "epoch: 1, train_total: 4672\n",
      "epoch: 1, train_total: 4736\n",
      "epoch: 1, train_total: 4800\n",
      "epoch: 1, train_total: 4864\n",
      "epoch: 1, train_total: 4928\n",
      "epoch: 1, train_total: 4992\n",
      "epoch: 1, train_total: 5056\n",
      "epoch: 1, train_total: 5120\n",
      "epoch: 1, train_total: 5184\n",
      "epoch: 1, train_total: 5248\n",
      "epoch: 1, train_total: 5312\n",
      "epoch: 1, train_total: 5376\n",
      "epoch: 1, train_total: 5440\n",
      "epoch: 1, train_total: 5504\n",
      "epoch: 1, train_total: 5568\n",
      "epoch: 1, train_total: 5632\n",
      "epoch: 1, train_total: 5696\n",
      "epoch: 1, train_total: 5760\n",
      "epoch: 1, train_total: 5824\n",
      "epoch: 1, train_total: 5888\n",
      "epoch: 1, train_total: 5952\n",
      "epoch: 1, train_total: 6016\n",
      "epoch: 1, train_total: 6080\n",
      "epoch: 1, train_total: 6144\n",
      "epoch: 1, train_total: 6208\n",
      "epoch: 1, train_total: 6272\n",
      "epoch: 1, train_total: 6336\n",
      "epoch: 1, train_total: 6400\n",
      "epoch: 1, train_total: 6464\n",
      "epoch: 1, train_total: 6528\n",
      "epoch: 1, train_total: 6592\n",
      "epoch: 1, train_total: 6656\n",
      "epoch: 1, train_total: 6720\n",
      "epoch: 1, train_total: 6784\n",
      "epoch: 1, train_total: 6848\n",
      "epoch: 1, train_total: 6912\n",
      "epoch: 1, train_total: 6976\n",
      "epoch: 1, train_total: 7040\n",
      "epoch: 1, train_total: 7104\n",
      "epoch: 1, train_total: 7168\n",
      "epoch: 1, train_total: 7232\n",
      "epoch: 1, train_total: 7296\n",
      "epoch: 1, train_total: 7360\n",
      "epoch: 1, train_total: 7424\n",
      "epoch: 1, train_total: 7488\n",
      "epoch: 1, train_total: 7552\n",
      "epoch: 1, train_total: 7616\n",
      "epoch: 1, train_total: 7680\n",
      "epoch: 1, train_total: 7744\n",
      "epoch: 1, train_total: 7808\n",
      "epoch: 1, train_total: 7872\n",
      "epoch: 1, train_total: 7936\n",
      "epoch: 1, train_total: 8000\n",
      "epoch: 1, train_total: 8064\n",
      "epoch: 1, train_total: 8128\n",
      "epoch: 1, train_total: 8192\n",
      "epoch: 1, train_total: 8256\n",
      "epoch: 1, train_total: 8320\n",
      "epoch: 1, train_total: 8384\n",
      "epoch: 1, train_total: 8448\n",
      "epoch: 1, train_total: 8512\n",
      "epoch: 1, train_total: 8576\n",
      "epoch: 1, train_total: 8640\n",
      "epoch: 1, train_total: 8704\n",
      "epoch: 1, train_total: 8768\n",
      "epoch: 1, train_total: 8832\n",
      "epoch: 1, train_total: 8896\n",
      "epoch: 1, train_total: 8960\n",
      "epoch: 1, train_total: 9024\n",
      "epoch: 1, train_total: 9088\n",
      "epoch: 1, train_total: 9152\n",
      "epoch: 1, train_total: 9216\n",
      "epoch: 1, train_total: 9280\n",
      "epoch: 1, train_total: 9344\n",
      "epoch: 1, train_total: 9408\n",
      "epoch: 1, train_total: 9472\n",
      "epoch: 1, train_total: 9536\n",
      "epoch: 1, train_total: 9600\n",
      "epoch: 1, train_total: 9664\n",
      "epoch: 1, train_total: 9728\n",
      "epoch: 1, train_total: 9792\n",
      "epoch: 1, train_total: 9856\n",
      "epoch: 1, train_total: 9920\n",
      "epoch: 1, train_total: 9984\n",
      "epoch: 1, train_total: 10000\n",
      "epoch: 1, val_total: 64\n",
      "epoch: 1, val_total: 128\n",
      "epoch: 1, val_total: 192\n",
      "epoch: 1, val_total: 256\n",
      "epoch: 1, val_total: 320\n",
      "epoch: 1, val_total: 384\n",
      "epoch: 1, val_total: 448\n",
      "epoch: 1, val_total: 512\n",
      "epoch: 1, val_total: 576\n",
      "epoch: 1, val_total: 640\n",
      "epoch: 1, val_total: 704\n",
      "epoch: 1, val_total: 768\n",
      "epoch: 1, val_total: 832\n",
      "epoch: 1, val_total: 896\n",
      "epoch: 1, val_total: 960\n",
      "epoch: 1, val_total: 1024\n",
      "epoch: 1, val_total: 1088\n",
      "epoch: 1, val_total: 1152\n",
      "epoch: 1, val_total: 1216\n",
      "epoch: 1, val_total: 1280\n",
      "epoch: 1, val_total: 1344\n",
      "epoch: 1, val_total: 1408\n",
      "epoch: 1, val_total: 1472\n",
      "epoch: 1, val_total: 1536\n",
      "epoch: 1, val_total: 1600\n",
      "epoch: 1, val_total: 1664\n",
      "epoch: 1, val_total: 1728\n",
      "epoch: 1, val_total: 1792\n",
      "epoch: 1, val_total: 1856\n",
      "epoch: 1, val_total: 1920\n",
      "epoch: 1, val_total: 1984\n",
      "epoch: 1, val_total: 2048\n",
      "epoch: 1, val_total: 2112\n",
      "epoch: 1, val_total: 2176\n",
      "epoch: 1, val_total: 2240\n",
      "epoch: 1, val_total: 2304\n",
      "epoch: 1, val_total: 2368\n",
      "epoch: 1, val_total: 2432\n",
      "epoch: 1, val_total: 2496\n",
      "epoch: 1, val_total: 2560\n",
      "epoch: 1, val_total: 2603\n",
      "Epoch 1/2, Training Loss: 1.8398, Validation Loss: 1.3783\n",
      "epoch: 2, train_total: 10064\n",
      "epoch: 2, train_total: 10128\n",
      "epoch: 2, train_total: 10192\n",
      "epoch: 2, train_total: 10256\n",
      "epoch: 2, train_total: 10320\n",
      "epoch: 2, train_total: 10384\n",
      "epoch: 2, train_total: 10448\n",
      "epoch: 2, train_total: 10512\n",
      "epoch: 2, train_total: 10576\n",
      "epoch: 2, train_total: 10640\n",
      "epoch: 2, train_total: 10704\n",
      "epoch: 2, train_total: 10768\n",
      "epoch: 2, train_total: 10832\n",
      "epoch: 2, train_total: 10896\n",
      "epoch: 2, train_total: 10960\n",
      "epoch: 2, train_total: 11024\n",
      "epoch: 2, train_total: 11088\n",
      "epoch: 2, train_total: 11152\n",
      "epoch: 2, train_total: 11216\n",
      "epoch: 2, train_total: 11280\n",
      "epoch: 2, train_total: 11344\n",
      "epoch: 2, train_total: 11408\n",
      "epoch: 2, train_total: 11472\n",
      "epoch: 2, train_total: 11536\n",
      "epoch: 2, train_total: 11600\n",
      "epoch: 2, train_total: 11664\n",
      "epoch: 2, train_total: 11728\n",
      "epoch: 2, train_total: 11792\n",
      "epoch: 2, train_total: 11856\n",
      "epoch: 2, train_total: 11920\n",
      "epoch: 2, train_total: 11984\n",
      "epoch: 2, train_total: 12048\n",
      "epoch: 2, train_total: 12112\n",
      "epoch: 2, train_total: 12176\n",
      "epoch: 2, train_total: 12240\n",
      "epoch: 2, train_total: 12304\n",
      "epoch: 2, train_total: 12368\n",
      "epoch: 2, train_total: 12432\n",
      "epoch: 2, train_total: 12496\n",
      "epoch: 2, train_total: 12560\n",
      "epoch: 2, train_total: 12624\n",
      "epoch: 2, train_total: 12688\n",
      "epoch: 2, train_total: 12752\n",
      "epoch: 2, train_total: 12816\n",
      "epoch: 2, train_total: 12880\n",
      "epoch: 2, train_total: 12944\n",
      "epoch: 2, train_total: 13008\n",
      "epoch: 2, train_total: 13072\n",
      "epoch: 2, train_total: 13136\n",
      "epoch: 2, train_total: 13200\n",
      "epoch: 2, train_total: 13264\n",
      "epoch: 2, train_total: 13328\n",
      "epoch: 2, train_total: 13392\n",
      "epoch: 2, train_total: 13456\n",
      "epoch: 2, train_total: 13520\n",
      "epoch: 2, train_total: 13584\n",
      "epoch: 2, train_total: 13648\n",
      "epoch: 2, train_total: 13712\n",
      "epoch: 2, train_total: 13776\n",
      "epoch: 2, train_total: 13840\n",
      "epoch: 2, train_total: 13904\n",
      "epoch: 2, train_total: 13968\n",
      "epoch: 2, train_total: 14032\n",
      "epoch: 2, train_total: 14096\n",
      "epoch: 2, train_total: 14160\n",
      "epoch: 2, train_total: 14224\n",
      "epoch: 2, train_total: 14288\n",
      "epoch: 2, train_total: 14352\n",
      "epoch: 2, train_total: 14416\n",
      "epoch: 2, train_total: 14480\n",
      "epoch: 2, train_total: 14544\n",
      "epoch: 2, train_total: 14608\n",
      "epoch: 2, train_total: 14672\n",
      "epoch: 2, train_total: 14736\n",
      "epoch: 2, train_total: 14800\n",
      "epoch: 2, train_total: 14864\n",
      "epoch: 2, train_total: 14928\n",
      "epoch: 2, train_total: 14992\n",
      "epoch: 2, train_total: 15056\n",
      "epoch: 2, train_total: 15120\n",
      "epoch: 2, train_total: 15184\n",
      "epoch: 2, train_total: 15248\n",
      "epoch: 2, train_total: 15312\n",
      "epoch: 2, train_total: 15376\n",
      "epoch: 2, train_total: 15440\n",
      "epoch: 2, train_total: 15504\n",
      "epoch: 2, train_total: 15568\n",
      "epoch: 2, train_total: 15632\n",
      "epoch: 2, train_total: 15696\n",
      "epoch: 2, train_total: 15760\n",
      "epoch: 2, train_total: 15824\n",
      "epoch: 2, train_total: 15888\n",
      "epoch: 2, train_total: 15952\n",
      "epoch: 2, train_total: 16016\n",
      "epoch: 2, train_total: 16080\n",
      "epoch: 2, train_total: 16144\n",
      "epoch: 2, train_total: 16208\n",
      "epoch: 2, train_total: 16272\n",
      "epoch: 2, train_total: 16336\n",
      "epoch: 2, train_total: 16400\n",
      "epoch: 2, train_total: 16464\n",
      "epoch: 2, train_total: 16528\n",
      "epoch: 2, train_total: 16592\n",
      "epoch: 2, train_total: 16656\n",
      "epoch: 2, train_total: 16720\n",
      "epoch: 2, train_total: 16784\n",
      "epoch: 2, train_total: 16848\n",
      "epoch: 2, train_total: 16912\n",
      "epoch: 2, train_total: 16976\n",
      "epoch: 2, train_total: 17040\n",
      "epoch: 2, train_total: 17104\n",
      "epoch: 2, train_total: 17168\n",
      "epoch: 2, train_total: 17232\n",
      "epoch: 2, train_total: 17296\n",
      "epoch: 2, train_total: 17360\n",
      "epoch: 2, train_total: 17424\n",
      "epoch: 2, train_total: 17488\n",
      "epoch: 2, train_total: 17552\n",
      "epoch: 2, train_total: 17616\n",
      "epoch: 2, train_total: 17680\n",
      "epoch: 2, train_total: 17744\n",
      "epoch: 2, train_total: 17808\n",
      "epoch: 2, train_total: 17872\n",
      "epoch: 2, train_total: 17936\n",
      "epoch: 2, train_total: 18000\n",
      "epoch: 2, train_total: 18064\n",
      "epoch: 2, train_total: 18128\n",
      "epoch: 2, train_total: 18192\n",
      "epoch: 2, train_total: 18256\n",
      "epoch: 2, train_total: 18320\n",
      "epoch: 2, train_total: 18384\n",
      "epoch: 2, train_total: 18448\n",
      "epoch: 2, train_total: 18512\n",
      "epoch: 2, train_total: 18576\n",
      "epoch: 2, train_total: 18640\n",
      "epoch: 2, train_total: 18704\n",
      "epoch: 2, train_total: 18768\n",
      "epoch: 2, train_total: 18832\n",
      "epoch: 2, train_total: 18896\n",
      "epoch: 2, train_total: 18960\n",
      "epoch: 2, train_total: 19024\n",
      "epoch: 2, train_total: 19088\n",
      "epoch: 2, train_total: 19152\n",
      "epoch: 2, train_total: 19216\n",
      "epoch: 2, train_total: 19280\n",
      "epoch: 2, train_total: 19344\n",
      "epoch: 2, train_total: 19408\n",
      "epoch: 2, train_total: 19472\n",
      "epoch: 2, train_total: 19536\n",
      "epoch: 2, train_total: 19600\n",
      "epoch: 2, train_total: 19664\n",
      "epoch: 2, train_total: 19728\n",
      "epoch: 2, train_total: 19792\n",
      "epoch: 2, train_total: 19856\n",
      "epoch: 2, train_total: 19920\n",
      "epoch: 2, train_total: 19984\n",
      "epoch: 2, train_total: 20000\n",
      "epoch: 2, val_total: 2667\n",
      "epoch: 2, val_total: 2731\n",
      "epoch: 2, val_total: 2795\n",
      "epoch: 2, val_total: 2859\n",
      "epoch: 2, val_total: 2923\n",
      "epoch: 2, val_total: 2987\n",
      "epoch: 2, val_total: 3051\n",
      "epoch: 2, val_total: 3115\n",
      "epoch: 2, val_total: 3179\n",
      "epoch: 2, val_total: 3243\n",
      "epoch: 2, val_total: 3307\n",
      "epoch: 2, val_total: 3371\n",
      "epoch: 2, val_total: 3435\n",
      "epoch: 2, val_total: 3499\n",
      "epoch: 2, val_total: 3563\n",
      "epoch: 2, val_total: 3627\n",
      "epoch: 2, val_total: 3691\n",
      "epoch: 2, val_total: 3755\n",
      "epoch: 2, val_total: 3819\n",
      "epoch: 2, val_total: 3883\n",
      "epoch: 2, val_total: 3947\n",
      "epoch: 2, val_total: 4011\n",
      "epoch: 2, val_total: 4075\n",
      "epoch: 2, val_total: 4139\n",
      "epoch: 2, val_total: 4203\n",
      "epoch: 2, val_total: 4267\n",
      "epoch: 2, val_total: 4331\n",
      "epoch: 2, val_total: 4395\n",
      "epoch: 2, val_total: 4459\n",
      "epoch: 2, val_total: 4523\n",
      "epoch: 2, val_total: 4587\n",
      "epoch: 2, val_total: 4651\n",
      "epoch: 2, val_total: 4715\n",
      "epoch: 2, val_total: 4779\n",
      "epoch: 2, val_total: 4843\n",
      "epoch: 2, val_total: 4907\n",
      "epoch: 2, val_total: 4971\n",
      "epoch: 2, val_total: 5035\n",
      "epoch: 2, val_total: 5099\n",
      "epoch: 2, val_total: 5163\n",
      "epoch: 2, val_total: 5206\n",
      "Epoch 2/2, Training Loss: 1.1414, Validation Loss: 1.0510\n",
      "\n",
      "Training Accuracy : 43.27% \n",
      "\n",
      "Validation Accuracy : 59.34% \n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_svhn_ft = Net_1Channel()\n",
    "\n",
    "# Load the model\n",
    "PATH = './mnist_net_cnn.pth'\n",
    "model_svhn_ft.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# No need the change the last layer as the last layer of the trained model is already having 10 outputs\n",
    "\n",
    "\n",
    "# set the loss function, criterion and other hyper parameters\n",
    "epochs_svhn_ft = 2\n",
    "LEARNING_RATE_svhn_ft = 0.001\n",
    "criterion_svhn_ft = nn.CrossEntropyLoss()\n",
    "optimizer_svhn_ft = torch.optim.Adam(model_svhn_ft.parameters(),lr=LEARNING_RATE_svhn_ft)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trained_model_svhn_ft = train_model(model_svhn_ft, criterion_svhn_ft, optimizer_svhn_ft, train_loader, val_loader, epochs_svhn_ft)\n",
    "\n",
    "\n",
    "# save the trained best model\n",
    "PATH = './model_svhn_ft.pth'\n",
    "torch.save(trained_model_svhn_ft.state_dict(), PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0642a04b-db88-460f-a4a5-15b1b018c7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 70.51% \n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "PATH = './model_svhn_ft.pth'\n",
    "trained_model_svhn_ft.load_state_dict(torch.load(PATH))\n",
    "tested_model = test_model(trained_model_svhn_ft,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589f52b-9fc1-41d4-a8d6-016bdcfd46db",
   "metadata": {},
   "source": [
    "## In the third step you are performing transfer learning from MNIST to SVHN (optional).\n",
    "\n",
    "Accuracy: 20.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf7866d0-f4e6-4b3e-bc25-16da1f3dd747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_1Channel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model_svhn_fe = Net_1Channel()\n",
    "\n",
    "# Load the CNN model that was trained on mnist data set\n",
    "PATH = './mnist_net_cnn.pth'\n",
    "model_svhn_fe.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# no need the change the last layer as the last layer of the trained model is already having 10 outputs\n",
    "\n",
    "# print model\n",
    "print(model_svhn_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1106b91-ea1a-4a62-8856-09857cb11ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the gradient update in all the layers\n",
    "for parameters in model_svhn_fe.parameters():\n",
    "    parameters.requires_grad = False\n",
    "\n",
    "# unfrezee the gradient update in the last layer\n",
    "model_svhn_fe.fc3.weight.requires_grad = True\n",
    "model_svhn_fe.fc3.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd984fd2-98a1-4681-9687-f74c12be8149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_total: 64\n",
      "epoch: 1, train_total: 128\n",
      "epoch: 1, train_total: 192\n",
      "epoch: 1, train_total: 256\n",
      "epoch: 1, train_total: 320\n",
      "epoch: 1, train_total: 384\n",
      "epoch: 1, train_total: 448\n",
      "epoch: 1, train_total: 512\n",
      "epoch: 1, train_total: 576\n",
      "epoch: 1, train_total: 640\n",
      "epoch: 1, train_total: 704\n",
      "epoch: 1, train_total: 768\n",
      "epoch: 1, train_total: 832\n",
      "epoch: 1, train_total: 896\n",
      "epoch: 1, train_total: 960\n",
      "epoch: 1, train_total: 1024\n",
      "epoch: 1, train_total: 1088\n",
      "epoch: 1, train_total: 1152\n",
      "epoch: 1, train_total: 1216\n",
      "epoch: 1, train_total: 1280\n",
      "epoch: 1, train_total: 1344\n",
      "epoch: 1, train_total: 1408\n",
      "epoch: 1, train_total: 1472\n",
      "epoch: 1, train_total: 1536\n",
      "epoch: 1, train_total: 1600\n",
      "epoch: 1, train_total: 1664\n",
      "epoch: 1, train_total: 1728\n",
      "epoch: 1, train_total: 1792\n",
      "epoch: 1, train_total: 1856\n",
      "epoch: 1, train_total: 1920\n",
      "epoch: 1, train_total: 1984\n",
      "epoch: 1, train_total: 2048\n",
      "epoch: 1, train_total: 2112\n",
      "epoch: 1, train_total: 2176\n",
      "epoch: 1, train_total: 2240\n",
      "epoch: 1, train_total: 2304\n",
      "epoch: 1, train_total: 2368\n",
      "epoch: 1, train_total: 2432\n",
      "epoch: 1, train_total: 2496\n",
      "epoch: 1, train_total: 2560\n",
      "epoch: 1, train_total: 2624\n",
      "epoch: 1, train_total: 2688\n",
      "epoch: 1, train_total: 2752\n",
      "epoch: 1, train_total: 2816\n",
      "epoch: 1, train_total: 2880\n",
      "epoch: 1, train_total: 2944\n",
      "epoch: 1, train_total: 3008\n",
      "epoch: 1, train_total: 3072\n",
      "epoch: 1, train_total: 3136\n",
      "epoch: 1, train_total: 3200\n",
      "epoch: 1, train_total: 3264\n",
      "epoch: 1, train_total: 3328\n",
      "epoch: 1, train_total: 3392\n",
      "epoch: 1, train_total: 3456\n",
      "epoch: 1, train_total: 3520\n",
      "epoch: 1, train_total: 3584\n",
      "epoch: 1, train_total: 3648\n",
      "epoch: 1, train_total: 3712\n",
      "epoch: 1, train_total: 3776\n",
      "epoch: 1, train_total: 3840\n",
      "epoch: 1, train_total: 3904\n",
      "epoch: 1, train_total: 3968\n",
      "epoch: 1, train_total: 4032\n",
      "epoch: 1, train_total: 4096\n",
      "epoch: 1, train_total: 4160\n",
      "epoch: 1, train_total: 4224\n",
      "epoch: 1, train_total: 4288\n",
      "epoch: 1, train_total: 4352\n",
      "epoch: 1, train_total: 4416\n",
      "epoch: 1, train_total: 4480\n",
      "epoch: 1, train_total: 4544\n",
      "epoch: 1, train_total: 4608\n",
      "epoch: 1, train_total: 4672\n",
      "epoch: 1, train_total: 4736\n",
      "epoch: 1, train_total: 4800\n",
      "epoch: 1, train_total: 4864\n",
      "epoch: 1, train_total: 4928\n",
      "epoch: 1, train_total: 4992\n",
      "epoch: 1, train_total: 5056\n",
      "epoch: 1, train_total: 5120\n",
      "epoch: 1, train_total: 5184\n",
      "epoch: 1, train_total: 5248\n",
      "epoch: 1, train_total: 5312\n",
      "epoch: 1, train_total: 5376\n",
      "epoch: 1, train_total: 5440\n",
      "epoch: 1, train_total: 5504\n",
      "epoch: 1, train_total: 5568\n",
      "epoch: 1, train_total: 5632\n",
      "epoch: 1, train_total: 5696\n",
      "epoch: 1, train_total: 5760\n",
      "epoch: 1, train_total: 5824\n",
      "epoch: 1, train_total: 5888\n",
      "epoch: 1, train_total: 5952\n",
      "epoch: 1, train_total: 6016\n",
      "epoch: 1, train_total: 6080\n",
      "epoch: 1, train_total: 6144\n",
      "epoch: 1, train_total: 6208\n",
      "epoch: 1, train_total: 6272\n",
      "epoch: 1, train_total: 6336\n",
      "epoch: 1, train_total: 6400\n",
      "epoch: 1, train_total: 6464\n",
      "epoch: 1, train_total: 6528\n",
      "epoch: 1, train_total: 6592\n",
      "epoch: 1, train_total: 6656\n",
      "epoch: 1, train_total: 6720\n",
      "epoch: 1, train_total: 6784\n",
      "epoch: 1, train_total: 6848\n",
      "epoch: 1, train_total: 6912\n",
      "epoch: 1, train_total: 6976\n",
      "epoch: 1, train_total: 7040\n",
      "epoch: 1, train_total: 7104\n",
      "epoch: 1, train_total: 7168\n",
      "epoch: 1, train_total: 7232\n",
      "epoch: 1, train_total: 7296\n",
      "epoch: 1, train_total: 7360\n",
      "epoch: 1, train_total: 7424\n",
      "epoch: 1, train_total: 7488\n",
      "epoch: 1, train_total: 7552\n",
      "epoch: 1, train_total: 7616\n",
      "epoch: 1, train_total: 7680\n",
      "epoch: 1, train_total: 7744\n",
      "epoch: 1, train_total: 7808\n",
      "epoch: 1, train_total: 7872\n",
      "epoch: 1, train_total: 7936\n",
      "epoch: 1, train_total: 8000\n",
      "epoch: 1, train_total: 8064\n",
      "epoch: 1, train_total: 8128\n",
      "epoch: 1, train_total: 8192\n",
      "epoch: 1, train_total: 8256\n",
      "epoch: 1, train_total: 8320\n",
      "epoch: 1, train_total: 8384\n",
      "epoch: 1, train_total: 8448\n",
      "epoch: 1, train_total: 8512\n",
      "epoch: 1, train_total: 8576\n",
      "epoch: 1, train_total: 8640\n",
      "epoch: 1, train_total: 8704\n",
      "epoch: 1, train_total: 8768\n",
      "epoch: 1, train_total: 8832\n",
      "epoch: 1, train_total: 8896\n",
      "epoch: 1, train_total: 8960\n",
      "epoch: 1, train_total: 9024\n",
      "epoch: 1, train_total: 9088\n",
      "epoch: 1, train_total: 9152\n",
      "epoch: 1, train_total: 9216\n",
      "epoch: 1, train_total: 9280\n",
      "epoch: 1, train_total: 9344\n",
      "epoch: 1, train_total: 9408\n",
      "epoch: 1, train_total: 9472\n",
      "epoch: 1, train_total: 9536\n",
      "epoch: 1, train_total: 9600\n",
      "epoch: 1, train_total: 9664\n",
      "epoch: 1, train_total: 9728\n",
      "epoch: 1, train_total: 9792\n",
      "epoch: 1, train_total: 9856\n",
      "epoch: 1, train_total: 9920\n",
      "epoch: 1, train_total: 9984\n",
      "epoch: 1, train_total: 10000\n",
      "epoch: 1, val_total: 64\n",
      "epoch: 1, val_total: 128\n",
      "epoch: 1, val_total: 192\n",
      "epoch: 1, val_total: 256\n",
      "epoch: 1, val_total: 320\n",
      "epoch: 1, val_total: 384\n",
      "epoch: 1, val_total: 448\n",
      "epoch: 1, val_total: 512\n",
      "epoch: 1, val_total: 576\n",
      "epoch: 1, val_total: 640\n",
      "epoch: 1, val_total: 704\n",
      "epoch: 1, val_total: 768\n",
      "epoch: 1, val_total: 832\n",
      "epoch: 1, val_total: 896\n",
      "epoch: 1, val_total: 960\n",
      "epoch: 1, val_total: 1024\n",
      "epoch: 1, val_total: 1088\n",
      "epoch: 1, val_total: 1152\n",
      "epoch: 1, val_total: 1216\n",
      "epoch: 1, val_total: 1280\n",
      "epoch: 1, val_total: 1344\n",
      "epoch: 1, val_total: 1408\n",
      "epoch: 1, val_total: 1472\n",
      "epoch: 1, val_total: 1536\n",
      "epoch: 1, val_total: 1600\n",
      "epoch: 1, val_total: 1664\n",
      "epoch: 1, val_total: 1728\n",
      "epoch: 1, val_total: 1792\n",
      "epoch: 1, val_total: 1856\n",
      "epoch: 1, val_total: 1920\n",
      "epoch: 1, val_total: 1984\n",
      "epoch: 1, val_total: 2048\n",
      "epoch: 1, val_total: 2112\n",
      "epoch: 1, val_total: 2176\n",
      "epoch: 1, val_total: 2240\n",
      "epoch: 1, val_total: 2304\n",
      "epoch: 1, val_total: 2368\n",
      "epoch: 1, val_total: 2432\n",
      "epoch: 1, val_total: 2496\n",
      "epoch: 1, val_total: 2560\n",
      "epoch: 1, val_total: 2603\n",
      "Epoch 1/2, Training Loss: 2.1948, Validation Loss: 2.1503\n",
      "epoch: 2, train_total: 10064\n",
      "epoch: 2, train_total: 10128\n",
      "epoch: 2, train_total: 10192\n",
      "epoch: 2, train_total: 10256\n",
      "epoch: 2, train_total: 10320\n",
      "epoch: 2, train_total: 10384\n",
      "epoch: 2, train_total: 10448\n",
      "epoch: 2, train_total: 10512\n",
      "epoch: 2, train_total: 10576\n",
      "epoch: 2, train_total: 10640\n",
      "epoch: 2, train_total: 10704\n",
      "epoch: 2, train_total: 10768\n",
      "epoch: 2, train_total: 10832\n",
      "epoch: 2, train_total: 10896\n",
      "epoch: 2, train_total: 10960\n",
      "epoch: 2, train_total: 11024\n",
      "epoch: 2, train_total: 11088\n",
      "epoch: 2, train_total: 11152\n",
      "epoch: 2, train_total: 11216\n",
      "epoch: 2, train_total: 11280\n",
      "epoch: 2, train_total: 11344\n",
      "epoch: 2, train_total: 11408\n",
      "epoch: 2, train_total: 11472\n",
      "epoch: 2, train_total: 11536\n",
      "epoch: 2, train_total: 11600\n",
      "epoch: 2, train_total: 11664\n",
      "epoch: 2, train_total: 11728\n",
      "epoch: 2, train_total: 11792\n",
      "epoch: 2, train_total: 11856\n",
      "epoch: 2, train_total: 11920\n",
      "epoch: 2, train_total: 11984\n",
      "epoch: 2, train_total: 12048\n",
      "epoch: 2, train_total: 12112\n",
      "epoch: 2, train_total: 12176\n",
      "epoch: 2, train_total: 12240\n",
      "epoch: 2, train_total: 12304\n",
      "epoch: 2, train_total: 12368\n",
      "epoch: 2, train_total: 12432\n",
      "epoch: 2, train_total: 12496\n",
      "epoch: 2, train_total: 12560\n",
      "epoch: 2, train_total: 12624\n",
      "epoch: 2, train_total: 12688\n",
      "epoch: 2, train_total: 12752\n",
      "epoch: 2, train_total: 12816\n",
      "epoch: 2, train_total: 12880\n",
      "epoch: 2, train_total: 12944\n",
      "epoch: 2, train_total: 13008\n",
      "epoch: 2, train_total: 13072\n",
      "epoch: 2, train_total: 13136\n",
      "epoch: 2, train_total: 13200\n",
      "epoch: 2, train_total: 13264\n",
      "epoch: 2, train_total: 13328\n",
      "epoch: 2, train_total: 13392\n",
      "epoch: 2, train_total: 13456\n",
      "epoch: 2, train_total: 13520\n",
      "epoch: 2, train_total: 13584\n",
      "epoch: 2, train_total: 13648\n",
      "epoch: 2, train_total: 13712\n",
      "epoch: 2, train_total: 13776\n",
      "epoch: 2, train_total: 13840\n",
      "epoch: 2, train_total: 13904\n",
      "epoch: 2, train_total: 13968\n",
      "epoch: 2, train_total: 14032\n",
      "epoch: 2, train_total: 14096\n",
      "epoch: 2, train_total: 14160\n",
      "epoch: 2, train_total: 14224\n",
      "epoch: 2, train_total: 14288\n",
      "epoch: 2, train_total: 14352\n",
      "epoch: 2, train_total: 14416\n",
      "epoch: 2, train_total: 14480\n",
      "epoch: 2, train_total: 14544\n",
      "epoch: 2, train_total: 14608\n",
      "epoch: 2, train_total: 14672\n",
      "epoch: 2, train_total: 14736\n",
      "epoch: 2, train_total: 14800\n",
      "epoch: 2, train_total: 14864\n",
      "epoch: 2, train_total: 14928\n",
      "epoch: 2, train_total: 14992\n",
      "epoch: 2, train_total: 15056\n",
      "epoch: 2, train_total: 15120\n",
      "epoch: 2, train_total: 15184\n",
      "epoch: 2, train_total: 15248\n",
      "epoch: 2, train_total: 15312\n",
      "epoch: 2, train_total: 15376\n",
      "epoch: 2, train_total: 15440\n",
      "epoch: 2, train_total: 15504\n",
      "epoch: 2, train_total: 15568\n",
      "epoch: 2, train_total: 15632\n",
      "epoch: 2, train_total: 15696\n",
      "epoch: 2, train_total: 15760\n",
      "epoch: 2, train_total: 15824\n",
      "epoch: 2, train_total: 15888\n",
      "epoch: 2, train_total: 15952\n",
      "epoch: 2, train_total: 16016\n",
      "epoch: 2, train_total: 16080\n",
      "epoch: 2, train_total: 16144\n",
      "epoch: 2, train_total: 16208\n",
      "epoch: 2, train_total: 16272\n",
      "epoch: 2, train_total: 16336\n",
      "epoch: 2, train_total: 16400\n",
      "epoch: 2, train_total: 16464\n",
      "epoch: 2, train_total: 16528\n",
      "epoch: 2, train_total: 16592\n",
      "epoch: 2, train_total: 16656\n",
      "epoch: 2, train_total: 16720\n",
      "epoch: 2, train_total: 16784\n",
      "epoch: 2, train_total: 16848\n",
      "epoch: 2, train_total: 16912\n",
      "epoch: 2, train_total: 16976\n",
      "epoch: 2, train_total: 17040\n",
      "epoch: 2, train_total: 17104\n",
      "epoch: 2, train_total: 17168\n",
      "epoch: 2, train_total: 17232\n",
      "epoch: 2, train_total: 17296\n",
      "epoch: 2, train_total: 17360\n",
      "epoch: 2, train_total: 17424\n",
      "epoch: 2, train_total: 17488\n",
      "epoch: 2, train_total: 17552\n",
      "epoch: 2, train_total: 17616\n",
      "epoch: 2, train_total: 17680\n",
      "epoch: 2, train_total: 17744\n",
      "epoch: 2, train_total: 17808\n",
      "epoch: 2, train_total: 17872\n",
      "epoch: 2, train_total: 17936\n",
      "epoch: 2, train_total: 18000\n",
      "epoch: 2, train_total: 18064\n",
      "epoch: 2, train_total: 18128\n",
      "epoch: 2, train_total: 18192\n",
      "epoch: 2, train_total: 18256\n",
      "epoch: 2, train_total: 18320\n",
      "epoch: 2, train_total: 18384\n",
      "epoch: 2, train_total: 18448\n",
      "epoch: 2, train_total: 18512\n",
      "epoch: 2, train_total: 18576\n",
      "epoch: 2, train_total: 18640\n",
      "epoch: 2, train_total: 18704\n",
      "epoch: 2, train_total: 18768\n",
      "epoch: 2, train_total: 18832\n",
      "epoch: 2, train_total: 18896\n",
      "epoch: 2, train_total: 18960\n",
      "epoch: 2, train_total: 19024\n",
      "epoch: 2, train_total: 19088\n",
      "epoch: 2, train_total: 19152\n",
      "epoch: 2, train_total: 19216\n",
      "epoch: 2, train_total: 19280\n",
      "epoch: 2, train_total: 19344\n",
      "epoch: 2, train_total: 19408\n",
      "epoch: 2, train_total: 19472\n",
      "epoch: 2, train_total: 19536\n",
      "epoch: 2, train_total: 19600\n",
      "epoch: 2, train_total: 19664\n",
      "epoch: 2, train_total: 19728\n",
      "epoch: 2, train_total: 19792\n",
      "epoch: 2, train_total: 19856\n",
      "epoch: 2, train_total: 19920\n",
      "epoch: 2, train_total: 19984\n",
      "epoch: 2, train_total: 20000\n",
      "epoch: 2, val_total: 2667\n",
      "epoch: 2, val_total: 2731\n",
      "epoch: 2, val_total: 2795\n",
      "epoch: 2, val_total: 2859\n",
      "epoch: 2, val_total: 2923\n",
      "epoch: 2, val_total: 2987\n",
      "epoch: 2, val_total: 3051\n",
      "epoch: 2, val_total: 3115\n",
      "epoch: 2, val_total: 3179\n",
      "epoch: 2, val_total: 3243\n",
      "epoch: 2, val_total: 3307\n",
      "epoch: 2, val_total: 3371\n",
      "epoch: 2, val_total: 3435\n",
      "epoch: 2, val_total: 3499\n",
      "epoch: 2, val_total: 3563\n",
      "epoch: 2, val_total: 3627\n",
      "epoch: 2, val_total: 3691\n",
      "epoch: 2, val_total: 3755\n",
      "epoch: 2, val_total: 3819\n",
      "epoch: 2, val_total: 3883\n",
      "epoch: 2, val_total: 3947\n",
      "epoch: 2, val_total: 4011\n",
      "epoch: 2, val_total: 4075\n",
      "epoch: 2, val_total: 4139\n",
      "epoch: 2, val_total: 4203\n",
      "epoch: 2, val_total: 4267\n",
      "epoch: 2, val_total: 4331\n",
      "epoch: 2, val_total: 4395\n",
      "epoch: 2, val_total: 4459\n",
      "epoch: 2, val_total: 4523\n",
      "epoch: 2, val_total: 4587\n",
      "epoch: 2, val_total: 4651\n",
      "epoch: 2, val_total: 4715\n",
      "epoch: 2, val_total: 4779\n",
      "epoch: 2, val_total: 4843\n",
      "epoch: 2, val_total: 4907\n",
      "epoch: 2, val_total: 4971\n",
      "epoch: 2, val_total: 5035\n",
      "epoch: 2, val_total: 5099\n",
      "epoch: 2, val_total: 5163\n",
      "epoch: 2, val_total: 5206\n",
      "Epoch 2/2, Training Loss: 2.1541, Validation Loss: 2.1289\n",
      "\n",
      "Training Accuracy : 19.66% \n",
      "\n",
      "Validation Accuracy : 21.95% \n"
     ]
    }
   ],
   "source": [
    "# set the loss function, criterion and other hyperparameters\n",
    "epochs_svhn_fe = 2\n",
    "LEARNING_RATE_svhn_fe = 0.001\n",
    "criterion_svhn_fe = nn.CrossEntropyLoss()\n",
    "optimizer_svhn_fe = torch.optim.Adam(model_svhn_fe.parameters(),lr=LEARNING_RATE_svhn_fe)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trained_model_svhn_fe = train_model(model_svhn_fe, criterion_svhn_fe, optimizer_svhn_fe, train_loader, val_loader, epochs_svhn_fe)\n",
    "\n",
    "\n",
    "# save the trained best model\n",
    "PATH = './model_svhn_fe.pth'\n",
    "torch.save(trained_model_svhn_fe.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63306ade-c870-49c4-b52e-478574991144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 22.27% \n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "PATH = './model_svhn_fe.pth'\n",
    "trained_model_svhn_fe.load_state_dict(torch.load(PATH))\n",
    "tested_model = test_model(trained_model_svhn_fe,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
